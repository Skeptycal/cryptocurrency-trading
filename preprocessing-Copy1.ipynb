{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import paratext\n",
    "import pandas\n",
    "import lz4.frame\n",
    "import gzip\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from plumbum.cmd import rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, filter_initial=True):\n",
    "  df = pq.read_table(filename).to_pandas()\n",
    "  if filter_initial:\n",
    "    df = df[df['Event Type'] != 'Initial']\n",
    "  return df\n",
    "\n",
    "def get_second_data(df, current_second):\n",
    "  time = sec2string(current_second)\n",
    "  return df.loc[df['Event Time'].values == time]\n",
    "\n",
    "def get_minute_data(df, current_minute):\n",
    "  time = min2string(current_minute)\n",
    "  next_time = min2string(current_minute + 1)\n",
    "  return df.loc[(df['Event Time'].values >= time) & (df['Event Time'].values < next_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec2string(sec):\n",
    "  m, s = divmod(sec, 60)\n",
    "  h, m = divmod(m, 60)\n",
    "  return \"%02d:%02d:%02d\" %(h, m, s)\n",
    "\n",
    "def min2string(minute):\n",
    "  h, m = divmod(minute, 60)\n",
    "  return \"%02d:%02d:00\" %(h, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_price(df_chunk, percent_change, prev_price, when):\n",
    "  df_chunk = filter_df(df_chunk, event_type='Fill')\n",
    "  if (len(df_chunk) == 0) or (percent_change == 0.0):\n",
    "    current_avg_price = prev_price\n",
    "  else:\n",
    "    if when == 'start':\n",
    "      current_avg_price = df_chunk.iloc[0, -1]\n",
    "    elif when == 'end':\n",
    "      current_avg_price = df_chunk.iloc[-1, -1]\n",
    "  return current_avg_price\n",
    "\n",
    "def calc_percent_change(current_price, prev_price):\n",
    "  try:\n",
    "    percent_change = (current_price - prev_price) / prev_price\n",
    "  except:\n",
    "    percent_change = None\n",
    "  return percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df_chunk, side=None, event_type=None, order_type=None):\n",
    "  if side is not None:\n",
    "    df_chunk = df_chunk.loc[df_chunk['Side'].values == side]\n",
    "  if event_type is not None:\n",
    "    df_chunk = df_chunk.loc[df_chunk['Event Type'].values == event_type]\n",
    "  if order_type is not None:\n",
    "    df_chunk = df_chunk.loc[df_chunk['Order Type'].values == order_type]\n",
    "  return df_chunk \n",
    "\n",
    "def get_frequency(df_chunk):\n",
    "  return len(df_chunk)\n",
    "             \n",
    "def get_volume(df_chunk, volume_type=None):\n",
    "  if volume_type=='filled':\n",
    "    return sum(df_chunk['Fill Price (USD)'] * df_chunk['Fill Quantity (BTC)'])\n",
    "  if volume_type=='unfilled':\n",
    "    return sum(df_chunk['Limit Price (USD)'] * df_chunk['Original Quantity (BTC)'])\n",
    "\n",
    "def calculate_percentage(value1, value2):\n",
    "  try:\n",
    "    percentage = value1 / (value1 + value2)\n",
    "  except:\n",
    "    percentage = None\n",
    "  return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, length):\n",
    "  onehot = [0.]*length\n",
    "  onehot[index] = 1.\n",
    "  return onehot\n",
    "    \n",
    "def extract_temporal_features(df_chunk):\n",
    "#   try:\n",
    "#     year, month, day = df_chunk['Event Date'].values[0].split('-')\n",
    "#   except:\n",
    "#     print(minute)\n",
    "  year, month, day = df_chunk['Event Date'].values[0].split('-')\n",
    "  day_of_week = int(datetime.datetime(int(year), int(month), int(day)).weekday())\n",
    "  hour = int(df_chunk['Event Time'].values[0][0:2])\n",
    "  month = int(month) - 1\n",
    "  return one_hot(month, 12), one_hot(day_of_week, 7), one_hot(hour, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Values to compute:\n",
    "\n",
    "# Price:\n",
    "# Percent change\n",
    "\n",
    "\n",
    "# Buys:\n",
    "# Volume of Filled Markets\n",
    "# Volume of Filled Limits\n",
    "# Volume of Placed Limits\n",
    "# Volume of Cancelled Limits\n",
    "\n",
    "# Frequency of Filled Markets\n",
    "# Frequency of Filled Limits\n",
    "# Frequency of Placed Limits\n",
    "# Frequency of Cancelled Limits\n",
    "\n",
    "\n",
    "# Sells:\n",
    "# Volume of Filled Markets\n",
    "# Volume of Filled Limits\n",
    "# Volume of Placed Limits\n",
    "# Frequency of Filled Markets\n",
    "# Frequency of Filled Limits\n",
    "# Frequency of Placed Limits\n",
    "\n",
    "# Frequency of Filled Markets\n",
    "# Frequency of Filled Limits\n",
    "# Frequency of Placed Limits\n",
    "# Frequency of Cancelled Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_freq(df_chunk, volume_type):\n",
    "  return get_volume(df_chunk, volume_type=volume_type), get_frequency(df_chunk)\n",
    "\n",
    "def get_raw_features(df_chunk, side=None):\n",
    "  x = {}\n",
    "  x['vol_markets'], x['freq_markets']                   = vol_freq(filter_df(df_chunk, side=side, event_type=None, order_type='market'), volume_type='filled')\n",
    "  x['vol_filled_limits'], x['freq_filled_limits']       = vol_freq(filter_df(df_chunk, side=side, event_type='Fill', order_type='limit'), volume_type='filled')\n",
    "  x['vol_placed_limits'], x['freq_placed_limits']       = vol_freq(filter_df(df_chunk, side=side, event_type='Place', order_type='limit'), volume_type='unfilled')\n",
    "  x['vol_cancelled_limits'], x['freq_cancelled_limits'] = vol_freq(filter_df(df_chunk, side=side, event_type='Cancel', order_type='limit'), volume_type='unfilled')  \n",
    "  return x \n",
    "\n",
    "def compute_features(x_buy, x_sell):\n",
    "  # Buys:\n",
    "  # -Volume of Filled Markets vs Filled Limits\n",
    "  # -Volume of Placed Limits vs Filled Limits\n",
    "  # -Frequency of Filled Markets vs Filled Limits\n",
    "  # -Frequency of Placed Limits vs Filled Limits\n",
    "\n",
    "  # Sells:\n",
    "  # -Volume of Filled Markets vs Filled Limits\n",
    "  # -Volume of Placed Limited vs Filled Limits\n",
    "  # -Frequency of Filled Markets vs Filled Limits\n",
    "  # -Frequency of Placed Limits vs Filled Limits\n",
    "\n",
    "  # Buys vs Sells:\n",
    "  # -Volume of Filled Market Sells vs Volume of Filled Market Buys\n",
    "  # -Volume of Placed Limit Sells vs Volume of Placed Limit Buys\n",
    "  # -Volume of Cancelled Limit Sells vs Volume Cancelled Limit Buys\n",
    "  # -Frequency of Filled Market Sells vs Frequency of Filled Market Buys\n",
    "  # -Frequency of Placed Limit Sells vs Frequency of Placed Limit Buys\n",
    "  # -Frequency of Cancelled Limit Sells vs Frequency of Cancelled Limit Buys\n",
    "  \n",
    "  features = []\n",
    "  # Buys:\n",
    "  features.append(calculate_percentage(x_buy['vol_markets'],        x_buy['vol_filled_limits']))\n",
    "  features.append(calculate_percentage(x_buy['vol_placed_limits'],  x_buy['vol_filled_limits']))\n",
    "  features.append(calculate_percentage(x_buy['freq_markets'],       x_buy['freq_filled_limits']))\n",
    "  features.append(calculate_percentage(x_buy['freq_placed_limits'], x_buy['freq_filled_limits']))\n",
    "\n",
    "  # Sells:\n",
    "  features.append(calculate_percentage(x_sell['vol_markets'],        x_sell['vol_filled_limits']))\n",
    "  features.append(calculate_percentage(x_sell['vol_placed_limits'],  x_sell['vol_filled_limits']))\n",
    "  features.append(calculate_percentage(x_sell['freq_markets'],       x_sell['freq_filled_limits']))\n",
    "  features.append(calculate_percentage(x_sell['freq_placed_limits'], x_sell['freq_filled_limits']))\n",
    "\n",
    "  # Buys vs Sells:\n",
    "  features.append(calculate_percentage(x_sell['vol_markets'],           x_buy['vol_markets']))\n",
    "  features.append(calculate_percentage(x_sell['vol_placed_limits'],     x_buy['vol_placed_limits']))\n",
    "  features.append(calculate_percentage(x_sell['vol_cancelled_limits'],  x_buy['vol_cancelled_limits']))\n",
    "  features.append(calculate_percentage(x_sell['freq_markets'],          x_buy['freq_markets']))\n",
    "  features.append(calculate_percentage(x_sell['freq_placed_limits'],    x_buy['freq_placed_limits']))\n",
    "  features.append(calculate_percentage(x_sell['freq_cancelled_limits'], x_buy['freq_cancelled_limits']))\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(df_chunk, percent_change, prev_price):\n",
    "  \n",
    "  # Current price, percent change\n",
    "  current_price = get_avg_price(df_chunk, percent_change, prev_price, when='end')\n",
    "  percent_change = calc_percent_change(current_price, prev_price)\n",
    "  \n",
    "  # Order book features\n",
    "  x_buy  = get_raw_features(df_chunk, side='buy')\n",
    "  x_sell = get_raw_features(df_chunk, side='sell')\n",
    "  feature_vec = compute_features(x_buy, x_sell)\n",
    "  \n",
    "  # Temporal features\n",
    "  month_vec, day_vec, hour_vec = extract_temporal_features(df_chunk)\n",
    "  feature_vec.extend(month_vec)\n",
    "  feature_vec.extend(day_vec)\n",
    "  feature_vec.extend(hour_vec)\n",
    "  \n",
    "  return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tmp_parquet(df, outfile):\n",
    "  outfile = outfile.replace('cboe/parquet_BTCUSD/', 'cboe/parquet_preprocessed_BTCUSD/')\n",
    "  pq.write_table(pa.Table.from_pandas(df), outfile, compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_day(filename, visualize=True, write_parquet=False, verbose=True):\n",
    "  print(filename)\n",
    "  df = load_data(filename, filter_initial=True)\n",
    "  \n",
    "  # Initialize previous price\n",
    "  percent_change=0.0\n",
    "  prev_price = get_avg_price(df, percent_change=percent_change, prev_price=None, when='start')\n",
    "  \n",
    "  # Compute feature vector for each minute of the day\n",
    "  all_X = []\n",
    "  for minute in range(24*60):\n",
    "    if verbose:\n",
    "      if minute%100 == 0:\n",
    "        print('Minutes:', minute)\n",
    "\n",
    "    # Select one minute of data from order book\n",
    "    df_chunk = get_minute_data(df, minute)\n",
    "    if len(df_chunk) == 0: # skip minutes with no data\n",
    "      continue\n",
    "    \n",
    "    # Extract features, X\n",
    "    #print(df_chunk)\n",
    "    #print(minute, prev_price)\n",
    "    X = get_all_features(df_chunk, percent_change, prev_price)\n",
    "    all_X.append(X)\n",
    "    prev_price = X[0]\n",
    "    percent_change = X[1]\n",
    "    \n",
    "  # Convert to pandas DF\n",
    "  new_df = pandas.DataFrame.from_records(all_X) \n",
    "  \n",
    "  # Compute labels, Y\n",
    "  new_df = calculate_y(new_df)\n",
    "  \n",
    "  # Write DF to tmp file to later be concatenated with all others\n",
    "  if write_parquet:\n",
    "    write_tmp_parquet(new_df, filename)\n",
    "\n",
    "  # Visualize\n",
    "  if visualize:\n",
    "    visualize_features(new_df)\n",
    "\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_of_events(df, timesteps, resolution='minute', event_type=None, order_type=None):\n",
    "  \n",
    "  # Filter data\n",
    "  if event_type is not None:\n",
    "    df = df.loc[df['Event Type'].values == event_type]\n",
    "  if order_type is not None:\n",
    "    df = df.loc[df['Order Type'].values == order_type]\n",
    "  \n",
    "  chunk_lengths = []\n",
    "  # Minute resolution\n",
    "  if resolution == 'minute':\n",
    "    for minute in range(timesteps):\n",
    "      chunk_lengths.append(len(get_minute_data(df, minute)))\n",
    "      if minute%200 == 0:\n",
    "        print('Minute:', minute)\n",
    "        \n",
    "  # Second resolution\n",
    "  elif resolution == 'second':\n",
    "    for sec in range(timesteps):\n",
    "      chunk_lengths.append(len(get_second_data(df, sec)))\n",
    "      if sec%100 == 0:\n",
    "        print('Second', sec)\n",
    "\n",
    "  # Visualize\n",
    "  plt.figure(figsize=(20,2));\n",
    "  plt.plot(chunk_lengths);\n",
    "  plt.figure(figsize=(20,5));\n",
    "  plt.hist(chunk_lengths, bins=40);\n",
    "  \n",
    "  return chunk_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_y(new_df):\n",
    "  new_df['y_percent_change'] = new_df['percent_change']\n",
    "  new_df['y_percent_change'] = new_df['y_percent_change'].shift(-1)\n",
    "  new_df = new_df[:-1]\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(df):\n",
    "  for column_idx in range(15):\n",
    "    plt.figure(figsize=(20,2));\n",
    "    df.plot(y = column_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize events\n",
    "# event_type = \"Fill\"\n",
    "# order_type = None\n",
    "# resolution = 'minute'\n",
    "# timesteps = 24*60\n",
    "\n",
    "# chunk_lengths = check_number_of_events(df, timesteps=timesteps, resolution=resolution,\n",
    "#                                        event_type=event_type, order_type=order_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_days = [0,100,200,300,400,600,800]\n",
    "for day in test_days:\n",
    "  filename = sorted(glob('cboe/parquet_BTCUSD/*.parquet'))[day]\n",
    "  new_df = preprocess_createXY_single_day(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all files\n",
    "filenames = sorted(glob('cboe/parquet_BTCUSD/*.parquet'))\n",
    "count = 0\n",
    "for filename in filenames:\n",
    "  preprocess_createXY_single_day(filename, visualize=False)\n",
    "  count += 1\n",
    "  print(count, '/', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cboe/parquet_BTCUSD/BTCUSD_order_book_20160425.parquet\n",
      "Minutes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes: 100\n",
      "Minutes: 200\n",
      "Minutes: 300\n",
      "Minutes: 400\n",
      "Minutes: 500\n",
      "Minutes: 600\n",
      "Minutes: 700\n",
      "Minutes: 800\n",
      "Minutes: 900\n",
      "Minutes: 1000\n",
      "Minutes: 1100\n",
      "Minutes: 1200\n",
      "Minutes: 1300\n",
      "Minutes: 1400\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'percent_change'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'percent_change'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-20b870b36951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_days\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cboe/parquet_BTCUSD/*.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-3fb03d869b60>\u001b[0m in \u001b[0;36mpreprocess_day\u001b[0;34m(filename, visualize, write_parquet, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# Compute labels, Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m# Write DF to tmp file to later be concatenated with all others\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-8751fde27c48>\u001b[0m in \u001b[0;36mcalculate_y\u001b[0;34m(new_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_percent_change'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_percent_change'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_percent_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'percent_change'"
     ]
    }
   ],
   "source": [
    "test_days = [760, 761, 861, 866]\n",
    "test_days = [200]\n",
    "for day in test_days:\n",
    "  filename = sorted(glob('cboe/parquet_BTCUSD/*.parquet'))[day]\n",
    "  new_df = preprocess_day(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
