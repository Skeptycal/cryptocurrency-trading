{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import lz4.frame\n",
    "import gzip\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from plumbum.cmd import rm\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import pickle\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotline(data):\n",
    "    plt.figure()\n",
    "    plt.plot(data)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def event_count(time_series, data_name):\n",
    "    time_series = time_series[['Fill Price (USD)']].values\n",
    "    upevents = 0\n",
    "    downevents = 0\n",
    "    sameprice = 0\n",
    "    prev_obv = time_series[0]\n",
    "    for obv in time_series[1:]:\n",
    "        if obv > prev_obv:\n",
    "            upevents += 1\n",
    "        elif obv < prev_obv:\n",
    "            downevents += 1\n",
    "        elif obv == prev_obv:\n",
    "            sameprice += 1\n",
    "        prev_obv = obv\n",
    "    print('=== Event counts on %s ===' % data_name)\n",
    "    print('upevents')\n",
    "    print(upevents)\n",
    "    print('downevents')\n",
    "    print(downevents)\n",
    "    print('sameprice')\n",
    "    print(sameprice)\n",
    "    print()\n",
    "\n",
    "def mse(time_series, data_name):\n",
    "    time_series = time_series[['Fill Price (USD)']].values\n",
    "    total_squared_error = 0\n",
    "    total_absolute_error = 0\n",
    "    prev_obv = time_series[0]\n",
    "    for obv in time_series[1:]:\n",
    "        total_squared_error += (obv - prev_obv)**2\n",
    "        total_absolute_error += abs(obv - prev_obv)\n",
    "        prev_obv = obv\n",
    "    num_predictions = len(time_series) - 1\n",
    "    mean_squared_error = total_squared_error / num_predictions\n",
    "    mean_absolute_error = total_absolute_error / num_predictions\n",
    "    root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "    print('=== baseline on %s ===' % data_name)\n",
    "    print('total squared error')\n",
    "    print(total_squared_error)\n",
    "    print('total absolute error')\n",
    "    print(total_absolute_error)\n",
    "    print('mean squared error')\n",
    "    print(mean_squared_error)\n",
    "    print('mean absolute error')\n",
    "    print(mean_absolute_error) \n",
    "    print('root mean squared error')\n",
    "    print(root_mean_squared_error) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_statistics():\n",
    "    #event_count(small_set, 'small')\n",
    "    train_set = df.iloc[0:num_samples_training]\n",
    "    dev_set = df.iloc[num_samples_training:num_samples_training+num_samples_dev]\n",
    "    test_set = df.iloc[num_samples_training+num_samples_dev:]\n",
    "    event_count(train_set, 'train')\n",
    "    event_count(dev_set, 'dev')\n",
    "    event_count(test_set, 'test')\n",
    "    mse(train_set, 'train')\n",
    "    mse(dev_set, 'dev')\n",
    "    mse(test_set, 'test')\n",
    "#show_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    values = np.array(data)\n",
    "    values = values.reshape(-1,1)\n",
    "    values = values.astype('float32') \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(model_history, title):\n",
    "    plt.figure()\n",
    "    plt.plot(model_history.history['loss'], label='Train')\n",
    "    plt.plot(model_history.history['val_loss'], label='Dev')\n",
    "    plt.xlabel('Epochs'); plt.ylabel('Loss (mse)')\n",
    "    plt.title(title)\n",
    "    plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, Y_test, Y_prevrawprice, title, inverse=False, scaler=None):\n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    if inverse:\n",
    "        y_hat = inverse_transform(y_hat, Y_prevrawprice, scaler)\n",
    "        Y_test = inverse_transform(Y_test, Y_prevrawprice, scaler)\n",
    "\n",
    "    plt.plot(y_hat, label='Predicted')\n",
    "    plt.plot(Y_test, label='True')\n",
    "    plt.xlabel('Time'); \n",
    "\n",
    "    if inverse:\n",
    "        plt.ylabel('Price')\n",
    "    else:\n",
    "        plt.ylabel('RESCALED Price')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE_RMSE(model, scaler, X_test, Y_test, Y_prevrawprice, model_name):\n",
    "    y_hat = model.predict(X_test)\n",
    "    y_hat_inverse = inverse_transform(y_hat, Y_prevrawprice, scaler)\n",
    "    Y_test_inverse = inverse_transform(Y_test, Y_prevrawprice, scaler)\n",
    "    mse = mean_squared_error(Y_test_inverse, y_hat_inverse)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test_inverse, y_hat_inverse))\n",
    "    print('%s:' % model_name)\n",
    "    print('Test MSE: %.3f' % mse)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_split=0.05, verbose=verbose, shuffle=False)\n",
    "    #train_evaluate_showresults(history, model, model_name, \n",
    "    #                 X_train, Y_train, X_dev, Y_dev, X_test, Y_test,\n",
    "    #                 lag, batch_size, epochs, verbose)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_showresults(history, model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "    # Plot losses, predictions, and calculate MSE and RMSE\n",
    "    plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_dev, Y_dev, Y_dev_prevrawprice, 'Test Predictions\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_dev, Y_dev, Y_dev_prevrawprice, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=price_scaler)\n",
    "    calculate_MSE_RMSE(model, price_scaler, X_dev, Y_dev, Y_dev_prevrawprice, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "    # Plot losses, predictions, and calculate MSE and RMSE\n",
    "    #plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_test, Y_test, Y_test_prevrawprice, 'Test Predictions\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_test, Y_test, Y_test_prevrawprice, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=price_scaler)\n",
    "    calculate_MSE_RMSE(model, price_scaler, X_test, Y_test, Y_test_prevrawprice, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(X_train, loss, optimizer, num_LSTMs, num_units, dropout, predict_end_of_window):\n",
    "    \n",
    "    LSTM_input_shape = [X_train.shape[1], X_train.shape[2]]\n",
    "    print('input shape is')\n",
    "    print(LSTM_input_shape)\n",
    "\n",
    "    # DEFINE MODEL\n",
    "    model = Sequential()\n",
    "\n",
    "    if num_LSTMs == 2:\n",
    "            model.add(LSTM(num_units[0], input_shape=LSTM_input_shape, return_sequences=True))\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "            if predict_end_of_window:\n",
    "              model.add(LSTM(num_units[1], return_sequences=False))\n",
    "            else:\n",
    "              model.add(LSTM(num_units[1], return_sequences=True))\n",
    "        \n",
    "    if num_LSTMs == 3:\n",
    "            model.add(LSTM(num_units[0], input_shape=LSTM_input_shape, return_sequences=True))\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "            model.add(LSTM(num_units[1], return_sequences=True))\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "            if predict_end_of_window:\n",
    "              model.add(LSTM(num_units[2], return_sequences=False))\n",
    "            else:\n",
    "              model.add(LSTM(num_units[2], return_sequences=True))\n",
    "\n",
    "    if predict_end_of_window:\n",
    "      model.add(TimeDistributed(Dense(1)))\n",
    "    else:\n",
    "      model.add(Dense(1))\n",
    "      \n",
    "    model.add(Activation('linear'))\n",
    "    \n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X(df):\n",
    "    n_all = df.shape[0]\n",
    "    n_train = round(n_all * 0.9)\n",
    "    n_dev   = round(n_all * 0.05)\n",
    "    n_test  = round(n_all * 0.05)\n",
    "    print('n_all:  ', n_all)\n",
    "    print('n_train:', n_train)\n",
    "    print('n_dev:  ', n_dev)\n",
    "    print('n_test: ', n_test)\n",
    "\n",
    "    X_train = df.iloc[:n_train, 1:16].values.astype('float32')\n",
    "    X_dev   = df.iloc[n_train:n_train+n_dev, 1:16].values.astype('float32')\n",
    "    X_test  = df.iloc[n_train+n_dev:, 1:16].values.astype('float32')\n",
    "    print(X_train.shape)\n",
    "    print(X_dev.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    return X_train, X_dev, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Y(df):\n",
    "    n_all = df.shape[0]\n",
    "    n_train = round(n_all * 0.9)\n",
    "    n_dev   = round(n_all * 0.05)\n",
    "    n_test  = round(n_all * 0.05)\n",
    "    Y_train = df.iloc[:n_train, -1:].values.astype('float32')\n",
    "    Y_dev   = df.iloc[n_train:n_train+n_dev, -1:].values.astype('float32')\n",
    "    Y_test  = df.iloc[n_train+n_dev:, -1:].values.astype('float32')\n",
    "    print(Y_train.shape)\n",
    "    print(Y_dev.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    return Y_train, Y_dev, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_parquet(df, outfile):\n",
    "    pq.write_table(pa.Table.from_pandas(df), outfile, compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_prediction(y_true, y_pred):\n",
    "    prop_correct = np.sum(np.sign(y_pred) == np.sign(y_true)) / (y_true.shape[0])\n",
    "    return prop_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, history, X_train, X_dev, X_test, Y_train, Y_dev, Y_test):\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    dev_loss   = history.history['val_loss'][-1]\n",
    "    test_loss  = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_dev   = model.predict(X_dev)\n",
    "    y_hat_test  = model.predict(X_test)\n",
    "    \n",
    "    train_prop_correct = direction_prediction(Y_train, y_hat_train)\n",
    "    dev_prop_correct   = direction_prediction(Y_dev, y_hat_dev)\n",
    "    test_prop_correct  = direction_prediction(Y_test, y_hat_test)\n",
    "    \n",
    "    evaluation = {'train_loss': train_loss,\n",
    "                  'dev_loss': dev_loss,\n",
    "                  'test_loss': test_loss,\n",
    "                  'train_prop_correct': train_prop_correct,\n",
    "                  'dev_prop_correct': dev_prop_correct,\n",
    "                  'test_prop_correct': test_prop_correct}\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequenced_data(data, window, step):\n",
    "    sequenced = []\n",
    "    for minute in range(0, len(data) - window, step):\n",
    "        chunk = data[minute:minute+window]\n",
    "        sequenced.append(chunk)\n",
    "    sequenced = np.array(sequenced)\n",
    "    return sequenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    X_train, X_dev, X_test = split_X(df)\n",
    "    Y_train, Y_dev, Y_test = split_Y(df)\n",
    "    return X_train, X_dev, X_test, Y_train, Y_dev, Y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, day_start=None, day_end=None):\n",
    "\n",
    "    # Concatenate dataframes\n",
    "    files = sorted(glob('%s/*.parquet' % path))\n",
    "    \n",
    "    if day_start is not None:\n",
    "        start = day_start\n",
    "    else:\n",
    "        start = 0\n",
    "    if day_end is not None:\n",
    "        end = day_start\n",
    "    else:\n",
    "        end = len(files)\n",
    "    files = files[start:end]\n",
    "    \n",
    "    all_dataframes = []\n",
    "    for file in files:\n",
    "        df = pq.read_table(file).to_pandas()\n",
    "        all_dataframes.append(df)\n",
    "    df = pd.concat(all_dataframes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_XY(X_train, X_dev, X_test, Y_train, Y_dev, Y_test, window_size, step, predict_end_of_window):\n",
    "    X_train = create_sequenced_data(X_train, window=window_size, step=step)\n",
    "    X_dev   = create_sequenced_data(X_dev,   window=window_size, step=step)\n",
    "    X_test  = create_sequenced_data(X_test,  window=window_size, step=step)\n",
    "\n",
    "    if predict_end_of_window:\n",
    "      Y_train = create_sequenced_data(Y_train, window=window_size, step=step)\n",
    "      Y_dev   = create_sequenced_data(Y_dev,   window=window_size, step=step)\n",
    "      Y_test  = create_sequenced_data(Y_test,  window=window_size, step=step)\n",
    "    else:\n",
    "      Y_train = create_sequenced_data(Y_train, window=window_size, step=step)\n",
    "      Y_dev   = create_sequenced_data(Y_dev,   window=window_size, step=step)\n",
    "      Y_test  = create_sequenced_data(Y_test,  window=window_size, step=step)\n",
    "    \n",
    "    print('Train, dev, test shapes:')\n",
    "    print(Y_train.shape)\n",
    "    print(X_dev.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(Y_dev.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    return X_train, X_dev, X_test, Y_train, Y_dev, Y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_history(model, history, model_path):\n",
    "    # serialize model to JSON\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        suffix = ''.join(re.findall(r'\\d+', str(datetime.datetime.now())))\n",
    "        model_path = model_path + '_' + suffix\n",
    "\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "    model_json = model.to_json()   \n",
    "    with open(model_path + '/model.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_path + '/model.h5')\n",
    "\n",
    "    print(\"Saved model and history to:\\n%s\" % model_path)\n",
    "\n",
    "    with open(model_path + '/trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_XY_predEndOfWindow(X_train, X_dev, X_test, Y_train, Y_dev, Y_test, window_size, step):\n",
    "  \n",
    "    X_train = create_sequenced_data(X_train, window=window_size, step=step)\n",
    "    X_dev   = create_sequenced_data(X_dev,   window=window_size, step=step)\n",
    "    X_test  = create_sequenced_data(X_test,  window=window_size, step=step)\n",
    "\n",
    "    Y_train = create_sequenced_data(Y_train, window=window_size, step=step)\n",
    "    Y_dev   = create_sequenced_data(Y_dev,   window=window_size, step=step)\n",
    "    Y_test  = create_sequenced_data(Y_test,  window=window_size, step=step)\n",
    "    \n",
    "    print('Train, dev, test shapes:')\n",
    "    print(Y_train.shape)\n",
    "    print(X_dev.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(Y_dev.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    return X_train, X_dev, X_test, Y_train, Y_dev, Y_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_all:   658758\n",
      "n_train: 592882\n",
      "n_dev:   32938\n",
      "n_test:  32938\n",
      "(592882, 15)\n",
      "(32938, 15)\n",
      "(32938, 15)\n",
      "(592882, 1)\n",
      "(32938, 1)\n",
      "(32938, 1)\n"
     ]
    }
   ],
   "source": [
    "## MAIN MODEL ##\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "window_size = 60\n",
    "step = 1\n",
    "\n",
    "batch_size = 8192\n",
    "num_epochs = 50\n",
    "verbose = 1\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adam'\n",
    "# num_LSTM = 3\n",
    "# num_units = [128, 256, 256]\n",
    "num_LSTM = 2\n",
    "num_units = [256, 256]\n",
    "dropout = 0.1\n",
    "\n",
    "path = 'cboe/parquet_preprocessed_BTCUSD_merged'\n",
    "day_start = 401\n",
    "day_end = None\n",
    "\n",
    "model_name = 'window-%s_step-%s_batch-%s_epochs-%s_loss-%s_opt-%s_numLSTMs-%s_numUnits-%s_dropout-%s' % (window_size, step, batch_size, num_epochs, loss, optimizer, num_LSTM, num_units, dropout)\n",
    "model_path = 'models/%s' % model_name\n",
    "\n",
    "# LOAD DATA\n",
    "df = load_data(path, day_start, day_end)\n",
    "\n",
    "# CREATE XY DATA\n",
    "X_train, X_dev, X_test, Y_train, Y_dev, Y_test = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00068536]\n",
      " [-0.00083374]\n",
      " [-0.00080732]\n",
      " [ 0.00419966]\n",
      " [ 0.00125001]\n",
      " [-0.00550523]\n",
      " [ 0.00177589]\n",
      " [ 0.00248398]\n",
      " [ 0.        ]\n",
      " [-0.00220427]]\n",
      "[[-0.00080732]\n",
      " [ 0.00125001]\n",
      " [ 0.00177589]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "window=3\n",
    "step=1\n",
    "print(Y_test[:10])\n",
    "print(Y_test[window-1:10:window-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_all:   658758\n",
      "n_train: 592882\n",
      "n_dev:   32938\n",
      "n_test:  32938\n",
      "(592882, 15)\n",
      "(32938, 15)\n",
      "(32938, 15)\n",
      "(592882, 1)\n",
      "(32938, 1)\n",
      "(32938, 1)\n",
      "Train, dev, test shapes:\n",
      "(592822, 60, 1)\n",
      "(32878, 60, 15)\n",
      "(32878, 60, 15)\n",
      "(592822, 60, 1)\n",
      "(32878, 60, 1)\n",
      "(32878, 60, 1)\n",
      "input shape is\n",
      "[60, 15]\n",
      "Train on 592822 samples, validate on 32878 samples\n",
      "Epoch 1/50\n",
      "592822/592822 [==============================] - 102s 172us/step - loss: 0.0077 - val_loss: 2.2958e-05\n",
      "Epoch 2/50\n",
      "592822/592822 [==============================] - 97s 164us/step - loss: 2.4588e-05 - val_loss: 1.3356e-05\n",
      "Epoch 3/50\n",
      "592822/592822 [==============================] - 97s 164us/step - loss: 1.4918e-05 - val_loss: 1.0932e-05\n",
      "Epoch 4/50\n",
      "592822/592822 [==============================] - 97s 164us/step - loss: 1.2197e-05 - val_loss: 9.4741e-06\n",
      "Epoch 5/50\n",
      "592822/592822 [==============================] - 97s 164us/step - loss: 1.0542e-05 - val_loss: 8.2874e-06\n",
      "Epoch 6/50\n",
      "592822/592822 [==============================] - 97s 164us/step - loss: 9.3355e-06 - val_loss: 7.4724e-06\n",
      "Epoch 7/50\n",
      "532480/592822 [=========================>....] - ETA: 9s - loss: 7.9299e-06 "
     ]
    }
   ],
   "source": [
    "## MAIN MODEL ##\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "window_size = 60\n",
    "step = 1\n",
    "\n",
    "batch_size = 8192\n",
    "num_epochs = 50\n",
    "verbose = 1\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adam'\n",
    "# num_LSTM = 3\n",
    "# num_units = [128, 256, 256]\n",
    "num_LSTM = 2\n",
    "num_units = [256, 256]\n",
    "dropout = 0.1\n",
    "\n",
    "path = 'cboe/parquet_preprocessed_BTCUSD_merged'\n",
    "day_start = 401\n",
    "day_end = None\n",
    "\n",
    "model_name = 'window-%s_step-%s_batch-%s_epochs-%s_loss-%s_opt-%s_numLSTMs-%s_numUnits-%s_dropout-%s' % (window_size, step, batch_size, num_epochs, loss, optimizer, num_LSTM, num_units, dropout)\n",
    "model_path = 'models/%s' % model_name\n",
    "\n",
    "# LOAD DATA\n",
    "df = load_data(path, day_start, day_end)\n",
    "\n",
    "# CREATE XY DATA\n",
    "X_train, X_dev, X_test, Y_train, Y_dev, Y_test = split(df)\n",
    "\n",
    "# X_train, X_dev, X_test, Y_train, Y_dev, Y_test = create_all_XY(X_train, X_dev, X_test, \n",
    "#                                                                Y_train, Y_dev, Y_test,\n",
    "#                                                                window_size, step)\n",
    "\n",
    "X_train, X_dev, X_test, Y_train, Y_dev, Y_test = create_all_XY_predEndOfWindow(X_train, X_dev, X_test, \n",
    "                                                               Y_train, Y_dev, Y_test,\n",
    "                                                               window_size, step)\n",
    "# INITIALIZE MODEL\n",
    "#model = initialize_model(X_train, loss, optimizer, num_LSTM, num_units, dropout, predict_end_of_window=False)\n",
    "model = initialize_model_predEndOfWindow(X_train, loss, optimizer, num_LSTM, num_units, \n",
    "                                         dropout, predict_end_of_window=True)\n",
    "\n",
    "# TRAIN MODEL\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                      validation_data=(X_dev, Y_dev), verbose=verbose, shuffle=False) \n",
    "\n",
    "# SAVE MODEL AND HISTORY\n",
    "save_model_history(model, history, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RESTORE MODEL:\n",
    "# # load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    " \n",
    "# # evaluate loaded model on test data\n",
    "# loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE MODEL\n",
    "evaluate = evaluate_model(model, history, X_train, X_dev, X_test, Y_train, Y_dev, Y_test)\n",
    "with open(model_path + '/evaluation.txt', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price(df):\n",
    "    plt.plot(df['current_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price(df, X_train, X_dev, field):\n",
    "    X_train_stop = len(X_train)\n",
    "    X_dev_stop = X_train_stop + len(X_dev)\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(np.arange(0, X_train_stop), df.iloc[0:X_train_stop][field], 'k')\n",
    "    plt.plot(np.arange(X_train_stop, X_dev_stop), df.iloc[X_train_stop:X_dev_stop][field], 'r')\n",
    "    plt.plot(np.arange(X_dev_stop, len(df)), df.iloc[X_dev_stop:len(df)][field], 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_dev_losses(history):\n",
    "    train_loss = history.history['loss']\n",
    "    dev_loss   = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(np.log(train_loss), 'k')\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(np.log(dev_loss), 'b')\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(train_loss, 'k')\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.plot(dev_loss, 'b')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percent_change(y_pred, y_true, timestep_within_window, minute_start, minute_end):\n",
    "    ys=[]\n",
    "    for i in range(len(y_pred)):\n",
    "        ys.append(y_pred[i][timestep_within_window])\n",
    "\n",
    "    original_ys=[]\n",
    "    for i in range(len(y_true)):\n",
    "        original_ys.append(y_true[i][timestep_within_window])\n",
    "\n",
    "    ys_orig = np.array(original_ys)\n",
    "    ys_pred = np.array(ys)\n",
    "    \n",
    "    \n",
    "    OldRange = (ys_pred.max() - ys_pred.min())  \n",
    "    NewRange = (ys_orig.max() - ys_orig.min())   \n",
    "    new_ys_pred = (((ys - ys_pred.min()) * NewRange) / OldRange) + ys_orig.min()\n",
    "    \n",
    "    \n",
    "    norm1 = ys_orig / np.linalg.norm(ys_orig)\n",
    "    norm2 = ys_pred / np.linalg.norm(ys_pred)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(norm1[minute_start:minute_end], 'k', alpha=0.9)\n",
    "    plt.plot(norm2[minute_start:minute_end], 'r', alpha=0.9)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(original_ys[minute_start:minute_end], 'k', alpha=0.9)\n",
    "    plt.plot(ys[minute_start:minute_end], 'r', alpha=0.9)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(original_ys[minute_start:minute_end], 'k', alpha=0.9)\n",
    "    plt.plot(new_ys_pred[minute_start:minute_end], 'r', alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test predictions\n",
    "y_hat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE\n",
    "## Plot: \n",
    "# Historical price, color coded with train, dev, test\n",
    "# Historical percent change, color coded with train, dev, test\n",
    "# Train Loss, Dev Loss\n",
    "# Actual price vs predicted price (or percent change) for test set\n",
    "# Example features time series for one day (NOTE: in the preprocessing_final notebook)\n",
    "\n",
    "timestep_within_window = 0\n",
    "minute_start = 0\n",
    "minute_end = len(Y_test)\n",
    "\n",
    "plot_price(df, X_train, X_dev, field='current_price')\n",
    "plot_price(df, X_train, X_dev, field='percent_change')\n",
    "plot_train_dev_losses(history)\n",
    "plot_percent_change(y_hat_test, Y_test, timestep_within_window, minute_start, minute_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
