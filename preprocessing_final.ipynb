{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas\n",
    "import lz4.frame\n",
    "import gzip\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from plumbum.cmd import rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, filter_initial=True):\n",
    "    df = pq.read_table(filename).to_pandas()\n",
    "    if filter_initial:\n",
    "        df = df[df['Event Type'] != 'Initial']\n",
    "        return df\n",
    "\n",
    "def get_second_data(df, current_second):\n",
    "    time = sec2string(current_second)\n",
    "    return df.loc[df['Event Time'].values == time]\n",
    "\n",
    "def get_minute_data(df, current_minute):\n",
    "    time = min2string(current_minute)\n",
    "    next_time = min2string(current_minute + 1)\n",
    "    return df.loc[(df['Event Time'].values >= time) & (df['Event Time'].values < next_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec2string(sec):\n",
    "    m, s = divmod(sec, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"%02d:%02d:%02d\" %(h, m, s)\n",
    "\n",
    "def min2string(minute):\n",
    "    h, m = divmod(minute, 60)\n",
    "    return \"%02d:%02d:00\" %(h, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_price(df_chunk, percent_change, prev_price, when):\n",
    "    df_chunk = filter_df(df_chunk, event_type='Fill')\n",
    "    if len(df_chunk) == 0:\n",
    "        current_avg_price = prev_price\n",
    "    else:\n",
    "        if when == 'start':\n",
    "            current_avg_price = df_chunk.iloc[0, -1]\n",
    "        elif when == 'end':\n",
    "            current_avg_price = df_chunk.iloc[-1, -1]\n",
    "    return current_avg_price\n",
    "\n",
    "def calc_percent_change(current_price, prev_price):\n",
    "    try:\n",
    "        percent_change = (current_price - prev_price) / prev_price\n",
    "    except:\n",
    "        percent_change = 0.0    \n",
    "    return percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df_chunk, side=None, event_type=None, order_type=None):\n",
    "    if side is not None:\n",
    "        df_chunk = df_chunk.loc[df_chunk['Side'].values == side]\n",
    "    if event_type is not None:\n",
    "        df_chunk = df_chunk.loc[df_chunk['Event Type'].values == event_type]\n",
    "    if order_type is not None:\n",
    "        df_chunk = df_chunk.loc[df_chunk['Order Type'].values == order_type]\n",
    "    return df_chunk \n",
    "\n",
    "def get_frequency(df_chunk):\n",
    "    return len(df_chunk)\n",
    "             \n",
    "def get_volume(df_chunk, volume_type=None):\n",
    "    if volume_type=='filled':\n",
    "        return sum(df_chunk['Fill Price (USD)'] * df_chunk['Fill Quantity (BTC)'])\n",
    "    if volume_type=='unfilled':\n",
    "        return sum(df_chunk['Limit Price (USD)'] * df_chunk['Original Quantity (BTC)'])\n",
    "\n",
    "def calculate_percentage(value1, value2):\n",
    "    if value1 == 0.0 and value2 == 0.0:\n",
    "        percentage = 0.5\n",
    "    else:\n",
    "        try:\n",
    "            percentage = value1 / (value1 + value2 + 1e-6)\n",
    "        except:\n",
    "            percentage = None\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, length):\n",
    "    onehot = [0.]*length\n",
    "    onehot[index] = 1.\n",
    "    return onehot\n",
    "    \n",
    "def extract_temporal_features(df_chunk):\n",
    "    year, month, day = df_chunk['Event Date'].values[0].split('-')\n",
    "    day_of_week = int(datetime.datetime(int(year), int(month), int(day)).weekday())\n",
    "    hour = int(df_chunk['Event Time'].values[0][0:2])\n",
    "    month = int(month) - 1\n",
    "    return one_hot(month, 12), one_hot(day_of_week, 7), one_hot(hour, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_freq(df_chunk, volume_type):\n",
    "    return get_volume(df_chunk, volume_type=volume_type), get_frequency(df_chunk)\n",
    "\n",
    "def get_raw_features(df_chunk, side=None):\n",
    "    x = {}\n",
    "    x['vol_markets'], x['freq_markets']                   = vol_freq(filter_df(df_chunk, side=side, event_type='Fill', order_type='market'), volume_type='filled')\n",
    "    x['vol_filled_limits'], x['freq_filled_limits']       = vol_freq(filter_df(df_chunk, side=side, event_type='Fill', order_type='limit'), volume_type='filled')\n",
    "    x['vol_placed_limits'], x['freq_placed_limits']       = vol_freq(filter_df(df_chunk, side=side, event_type='Place', order_type='limit'), volume_type='unfilled')\n",
    "    x['vol_cancelled_limits'], x['freq_cancelled_limits'] = vol_freq(filter_df(df_chunk, side=side, event_type='Cancel', order_type='limit'), volume_type='unfilled')  \n",
    "    return x \n",
    "\n",
    "def compute_features(x_buy, x_sell):\n",
    "    # Buys:\n",
    "    # -Volume of Filled Markets vs Filled Limits\n",
    "    # -Volume of Placed Limits vs Filled Limits\n",
    "    # -Frequency of Filled Markets vs Filled Limits\n",
    "    # -Frequency of Placed Limits vs Filled Limits\n",
    "\n",
    "    # Sells:\n",
    "    # -Volume of Filled Markets vs Filled Limits\n",
    "    # -Volume of Placed Limited vs Filled Limits\n",
    "    # -Frequency of Filled Markets vs Filled Limits\n",
    "    # -Frequency of Placed Limits vs Filled Limits\n",
    "\n",
    "    # Buys vs Sells:\n",
    "    # -Volume of Filled Market Sells vs Volume of Filled Market Buys\n",
    "    # -Volume of Placed Limit Sells vs Volume of Placed Limit Buys\n",
    "    # -Volume of Cancelled Limit Sells vs Volume Cancelled Limit Buys\n",
    "    # -Frequency of Filled Market Sells vs Frequency of Filled Market Buys\n",
    "    # -Frequency of Placed Limit Sells vs Frequency of Placed Limit Buys\n",
    "    # -Frequency of Cancelled Limit Sells vs Frequency of Cancelled Limit Buys\n",
    "\n",
    "    features = []\n",
    "    # Buys:\n",
    "    features.append(calculate_percentage(x_buy['vol_markets'],        x_buy['vol_filled_limits']))\n",
    "    features.append(calculate_percentage(x_buy['vol_placed_limits'],  x_buy['vol_filled_limits']))\n",
    "    features.append(calculate_percentage(x_buy['freq_markets'],       x_buy['freq_filled_limits']))\n",
    "    features.append(calculate_percentage(x_buy['freq_placed_limits'], x_buy['freq_filled_limits']))\n",
    "\n",
    "    # Sells:\n",
    "    features.append(calculate_percentage(x_sell['vol_markets'],        x_sell['vol_filled_limits']))\n",
    "    features.append(calculate_percentage(x_sell['vol_placed_limits'],  x_sell['vol_filled_limits']))\n",
    "    features.append(calculate_percentage(x_sell['freq_markets'],       x_sell['freq_filled_limits']))\n",
    "    features.append(calculate_percentage(x_sell['freq_placed_limits'], x_sell['freq_filled_limits']))\n",
    "\n",
    "    # Buys vs Sells:\n",
    "    features.append(calculate_percentage(x_sell['vol_markets'],           x_buy['vol_markets']))\n",
    "    features.append(calculate_percentage(x_sell['vol_placed_limits'],     x_buy['vol_placed_limits']))\n",
    "    features.append(calculate_percentage(x_sell['vol_cancelled_limits'],  x_buy['vol_cancelled_limits']))\n",
    "    features.append(calculate_percentage(x_sell['freq_markets'],          x_buy['freq_markets']))\n",
    "    features.append(calculate_percentage(x_sell['freq_placed_limits'],    x_buy['freq_placed_limits']))\n",
    "    features.append(calculate_percentage(x_sell['freq_cancelled_limits'], x_buy['freq_cancelled_limits']))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(df_chunk, percent_change, prev_price):\n",
    "  \n",
    "    # Current price, percent change\n",
    "    current_price = get_avg_price(df_chunk, percent_change, prev_price, when='end')\n",
    "    percent_change = calc_percent_change(current_price, prev_price)\n",
    "\n",
    "    feature_vec = [current_price, percent_change]\n",
    "\n",
    "    # Order book features\n",
    "    x_buy  = get_raw_features(df_chunk, side='buy')\n",
    "    x_sell = get_raw_features(df_chunk, side='sell')\n",
    "    feature_vec.extend(compute_features(x_buy, x_sell))\n",
    "\n",
    "    # Temporal features\n",
    "    month_vec, day_vec, hour_vec = extract_temporal_features(df_chunk)\n",
    "    feature_vec.extend(month_vec)\n",
    "    feature_vec.extend(day_vec)\n",
    "    feature_vec.extend(hour_vec)\n",
    "\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tmp_parquet(df, outfile):\n",
    "    outfile = outfile.replace('cboe/parquet_BTCUSD/', 'cboe/parquet_preprocessed_BTCUSD/')\n",
    "    pq.write_table(pa.Table.from_pandas(df), outfile, compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_day(filename, visualize=True, write_parquet=False, verbose=True):\n",
    "    print(filename)\n",
    "    df = load_data(filename, filter_initial=True)\n",
    "\n",
    "    # Initialize previous price\n",
    "    percent_change=0.0\n",
    "    prev_price = get_avg_price(df, percent_change=None, prev_price=None, when='start')\n",
    "\n",
    "    # Compute feature vector for each minute of the day\n",
    "    all_X = []\n",
    "    for minute in range(24*60):\n",
    "        if verbose:\n",
    "            if minute%100 == 0:\n",
    "                print('Minutes:', minute)\n",
    "\n",
    "        # Select one minute of data from order book\n",
    "        df_chunk = get_minute_data(df, minute)\n",
    "        if len(df_chunk) == 0: # skip minutes with no data\n",
    "            continue\n",
    "    \n",
    "        # Extract features, X\n",
    "        X = get_all_features(df_chunk, percent_change, prev_price)\n",
    "        prev_price = X[0]\n",
    "        percent_change = X[1]\n",
    "        #all_X.append(X[1:])\n",
    "        all_X.append(X)\n",
    "\n",
    "    #columns = ['current_price','percent_change',\n",
    "    columns = ['current_price', 'percent_change',\n",
    "               'buy_vol_mark_vs_fillLim','buy_vol_placeLim_vs_fillLim','buy_freq_mark_vs_fillLim','buy_freq_placeLim_vs_fillLim',\n",
    "               'sell_vol_mark_vs_fillLim','sell_vol_placeLim_vs_fillLim','sell_freq_mark_vs_fillLim','sell_freq_placeLim_vs_fillLim',\n",
    "               'vol_markSells_vs_markBuys','vol_placeLimSells_vs_placeLimBuys','vol_CancelLimSells_vs_CancelLimBuys',\n",
    "               'freq_markSells_vs_markBuys','freq_placeLimSells_vs_placeLimBuys','freq_CancelLimSells_vs_CancelLimBuys',\n",
    "               'm0','m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11',\n",
    "               'd0','d1','d2','d3','d4','d5','d6',\n",
    "               'h0','h1','h2','h3','h4','h5','h6','h7','h8','h9','h10','h11',\n",
    "               'h12','h13','h14','h15','h16','h17','h18','h19','h20','h21','h22','h23']\n",
    "    \n",
    "    # Convert to pandas DF\n",
    "    new_df = pandas.DataFrame.from_records(all_X, columns=columns) \n",
    "  \n",
    "    # Compute labels, Y\n",
    "    new_df = calculate_y(new_df)\n",
    "  \n",
    "    # Write DF to tmp file to later be concatenated with all others\n",
    "    if write_parquet:\n",
    "        write_tmp_parquet(new_df, filename)\n",
    "\n",
    "    # Visualize\n",
    "    if visualize:\n",
    "        visualize_features(new_df)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_of_events(df, timesteps, resolution='minute', event_type=None, order_type=None):\n",
    "  \n",
    "    # Filter data\n",
    "    if event_type is not None:\n",
    "        df = df.loc[df['Event Type'].values == event_type]\n",
    "    if order_type is not None:\n",
    "        df = df.loc[df['Order Type'].values == order_type]\n",
    "  \n",
    "    chunk_lengths = []\n",
    "    # Minute resolution\n",
    "    if resolution == 'minute':\n",
    "        for minute in range(timesteps):\n",
    "            chunk_lengths.append(len(get_minute_data(df, minute)))\n",
    "            if minute%200 == 0:\n",
    "                print('Minute:', minute)\n",
    "        \n",
    "    # Second resolution\n",
    "    elif resolution == 'second':\n",
    "        for sec in range(timesteps):\n",
    "            chunk_lengths.append(len(get_second_data(df, sec)))\n",
    "            if sec%100 == 0:\n",
    "                print('Second', sec)\n",
    "\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(20,2));\n",
    "    plt.plot(chunk_lengths);\n",
    "    plt.figure(figsize=(20,5));\n",
    "    plt.hist(chunk_lengths, bins=40);\n",
    "\n",
    "    return chunk_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_y(new_df):\n",
    "    new_df['y_percent_change'] = new_df.iloc[:,1]\n",
    "    new_df['y_percent_change'] = new_df['y_percent_change'].shift(-1)\n",
    "    new_df = new_df[:-1]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(df):\n",
    "    for column_idx in range(16):\n",
    "        title = df.columns[column_idx]\n",
    "        df.plot(y = column_idx, figsize=(20,2), title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize events\n",
    "# event_type = \"Fill\"\n",
    "# order_type = None\n",
    "# resolution = 'minute'\n",
    "# timesteps = 24*60\n",
    "\n",
    "# chunk_lengths = check_number_of_events(df, timesteps=timesteps, resolution=resolution,\n",
    "#                                        event_type=event_type, order_type=order_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess all files\n",
    "count = 0\n",
    "filenames = sorted(glob('cboe/parquet_BTCUSD/*.parquet'))\n",
    "filenames.reverse()\n",
    "for day in range(len(filenames)):\n",
    "    filename = filenames[day]\n",
    "    new_df = preprocess_day(filename, write_parquet=True, visualize=False, verbose=False)\n",
    "    count += 1\n",
    "    print(count, '/', len(filenames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
