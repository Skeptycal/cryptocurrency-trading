{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import lz4.frame\n",
    "import gzip\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "filepath = 'cboe/lz4_test/BTCUSD_order_book_20170627.csv.lz4'\n",
    "#filepath = 'cboe/lz4_test/BTCUSD_order_book_20170627.csv.gz'\n",
    "df = pandas.read_csv(io.TextIOWrapper(lz4.frame.open(filepath)))\n",
    "#df = pandas.read_csv(filepath)\n",
    "#df = paratext.load_csv_to_pandas(gzip.open(filepath).read())\n",
    "print((df))\n",
    "'''\n",
    "\n",
    "from glob import glob\n",
    "from plumbum.cmd import rm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/cryptocurrency-trading-geza'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotline(data):\n",
    "    plt.figure()\n",
    "    plt.plot(data)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 16936861696",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-094daf99f6a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mlist_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 16936861696"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pq.read_table('cboe/parquet_fills_only_BTCUSD.parquet').to_pandas()\n",
    "print(df.dtypes)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = df.shape[0] - 2 # subtract 1 because we exclude the first prediction, and another 1 because our feature is price differences\n",
    "num_samples_training = round(num_samples * 0.9)\n",
    "num_samples_dev = round(num_samples * 0.05)\n",
    "num_samples_test = round(num_samples * 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = df.iloc[0:num_samples_training]\n",
    "#dev_set = df.iloc[num_samples_training:num_samples_training+num_samples_dev]\n",
    "#test_set = df.iloc[num_samples_training+num_samples_dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_set = df.iloc[0:10]\n",
    "#print(small_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df['Event Date'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df['Avg Price (USD)'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df['Limit Price (USD)'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df['Fill Price (USD)'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_scaler = MinMaxScaler().fit(df.iloc[0:num_samples_training]['Fill Price (USD)'].values.reshape(-1, 1))\n",
    "\n",
    "def get_max_min_price(fulldata):\n",
    "  max_price = data[['Fill Price (USD)']].max().item()\n",
    "  min_price = data[['Fill Price (USD)']].min().item()\n",
    "  return {\n",
    "    'max': max_price,\n",
    "    'min': min_price\n",
    "  }\n",
    "\n",
    "\n",
    "\n",
    "def extract_price_features(fulldata):\n",
    "  data = fulldata[['Fill Price (USD)', 'Side', 'Order Type']].copy()\n",
    "  length = data.shape[0]\n",
    "  data['isbuy'] = pd.get_dummies(data['Side'])['buy'].values\n",
    "  data['ismarket'] = pd.get_dummies(data['Order Type'])['market'].values\n",
    "  data['price_scaled'] = price_scaler.transform(data['Fill Price (USD)'].values.reshape(-1, 1)).flatten()\n",
    "  return data[['price_scaled', 'isbuy', 'ismarket']].iloc[:length - 1].values.astype('float32')[:, None, :]\n",
    "  #return data[['price_scaled', 'isbuy', 'ismarket']].iloc[:length - 1].values[:, None, :]\n",
    "\n",
    "def extract_price_features_percentdiff(fulldata):\n",
    "  data = fulldata[['Fill Price (USD)', 'Side', 'Order Type']].copy()\n",
    "  length = data.shape[0]\n",
    "  data['isbuy'] = pd.get_dummies(data['Side'])['buy'].values\n",
    "  data['ismarket'] = pd.get_dummies(data['Order Type'])['market'].values\n",
    "  data['price_diff_percent'] = data['Fill Price (USD)'].pct_change()\n",
    "  return data[['price_diff_percent', 'isbuy', 'ismarket']].iloc[:length - 1].values.astype('float32')[1:, None, :]\n",
    "  #return data[['price_scaled', 'isbuy', 'ismarket']].iloc[:length - 1].values[:, None, :]\n",
    "\n",
    "\n",
    "extract_features = extract_price_features_percentdiff\n",
    "\n",
    "#small_features = extract_features(small_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_price_features_percentdiff(df.iloc[0:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = extract_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_samples = all_features.shape[0]\n",
    "#num_samples_training = round(num_samples * 0.9)\n",
    "#num_samples_dev = round(num_samples * 0.05)\n",
    "#num_samples_test = round(num_samples * 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_features[0:num_samples_training, :]\n",
    "X_dev = all_features[num_samples_training:num_samples_training+num_samples_dev, :]\n",
    "X_test = all_features[num_samples_training+num_samples_dev:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:,0,0].max())\n",
    "print(X_train[:,0,0].min())\n",
    "print(X_dev[:,0,0].max())\n",
    "print(X_dev[:,0,0].min())\n",
    "print(X_test[:,0,0].max())\n",
    "print(X_test[:,0,0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_y_rawprice(fulldata):\n",
    "  prices = fulldata[['Fill Price (USD)']].values.astype('float32')\n",
    "  #prices = fulldata[['Fill Price (USD)']].values\n",
    "  prices = price_scaler.transform(fulldata['Fill Price (USD)'].values.reshape(-1, 1)).flatten()\n",
    "  return np.delete(prices, 0, axis=0).reshape(-1, 1)\n",
    "  #return np.insert(prices, 0, prices[0])\n",
    "\n",
    "def extract_y_prevrawprice(fulldata):\n",
    "  prices = fulldata[['Fill Price (USD)']].values.astype('float32')\n",
    "  #prices = fulldata[['Fill Price (USD)']].values\n",
    "  prices = fulldata['Fill Price (USD)'].values.flatten()\n",
    "  return np.delete(prices, [0, prices.shape[0] - 1], axis=0).reshape(-1, 1)\n",
    "  #return np.insert(prices, 0, prices[0])\n",
    "\n",
    "def extract_y_percentdiff(fulldata):\n",
    "  #prices = fulldata[['Fill Price (USD)']].values\n",
    "  prices = fulldata['Fill Price (USD)'].pct_change().values.astype('float32')\n",
    "  return np.delete(prices, [0, 1], axis=0).reshape(-1, 1)\n",
    "  #return np.insert(prices, 0, prices[0])\n",
    "\n",
    "extract_y = extract_y_percentdiff\n",
    "\n",
    "#print(len(extract_y(small_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_y_prevrawprice(df.iloc[0:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_y_percentdiff(df.iloc[0:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = extract_y(df)\n",
    "all_y_prevrawprice = extract_y_prevrawprice(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_features.shape)\n",
    "print(all_y.shape)\n",
    "print(all_features.dtype)\n",
    "print(all_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = all_y[0:num_samples_training, :]\n",
    "Y_dev = all_y[num_samples_training:num_samples_training+num_samples_dev, :]\n",
    "Y_test = all_y[num_samples_training+num_samples_dev:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_prevrawprice = all_y_prevrawprice[0:num_samples_training, :]\n",
    "Y_dev_prevrawprice = all_y_prevrawprice[num_samples_training:num_samples_training+num_samples_dev, :]\n",
    "Y_test_prevrawprice = all_y_prevrawprice[num_samples_training+num_samples_dev:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[:,0].max())\n",
    "print(Y_train[:,0].min())\n",
    "print(Y_dev[:,0].max())\n",
    "print(Y_dev[:,0].min())\n",
    "print(Y_test[:,0].max())\n",
    "print(Y_test[:,0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotline(X_train[:,0,0])\n",
    "plotline(X_dev[:,0,0])\n",
    "plotline(X_test[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotline(df['Fill Price (USD)'].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotline(all_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotline(Y_train[:,0])\n",
    "plotline(Y_dev[:,0])\n",
    "plotline(Y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the training set smaller so we train faster\n",
    "downscaling_factor = 1\n",
    "#downscaling_factor = 100\n",
    "fraction_used = 1 / downscaling_factor\n",
    "fraction_skipped = 1 - fraction_used\n",
    "samples_skipped = round(X_train.shape[0] * fraction_skipped)\n",
    "print(X_train.shape)\n",
    "#X_train = X_train[::downscaling_factor]\n",
    "#Y_train = Y_train[::downscaling_factor]\n",
    "X_train = X_train[samples_skipped::]\n",
    "Y_train = Y_train[samples_skipped::]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = all_features[0:10]\n",
    "Y_sample = all_y[0:10]\n",
    "print(X_sample)\n",
    "print(Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_count(time_series, data_name):\n",
    "  time_series = time_series[['Fill Price (USD)']].values\n",
    "  upevents = 0\n",
    "  downevents = 0\n",
    "  sameprice = 0\n",
    "  prev_obv = time_series[0]\n",
    "  for obv in time_series[1:]:\n",
    "      if obv > prev_obv:\n",
    "          upevents += 1\n",
    "      elif obv < prev_obv:\n",
    "          downevents += 1\n",
    "      elif obv == prev_obv:\n",
    "          sameprice += 1\n",
    "      prev_obv = obv\n",
    "  print('=== Event counts on %s ===' % data_name)\n",
    "  print('upevents')\n",
    "  print(upevents)\n",
    "  print('downevents')\n",
    "  print(downevents)\n",
    "  print('sameprice')\n",
    "  print(sameprice)\n",
    "  print()\n",
    "\n",
    "def mse(time_series, data_name):\n",
    "  time_series = time_series[['Fill Price (USD)']].values\n",
    "  total_squared_error = 0\n",
    "  total_absolute_error = 0\n",
    "  prev_obv = time_series[0]\n",
    "  for obv in time_series[1:]:\n",
    "    total_squared_error += (obv - prev_obv)**2\n",
    "    total_absolute_error += abs(obv - prev_obv)\n",
    "    prev_obv = obv\n",
    "  num_predictions = len(time_series) - 1\n",
    "  mean_squared_error = total_squared_error / num_predictions\n",
    "  mean_absolute_error = total_absolute_error / num_predictions\n",
    "  root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "  print('=== baseline on %s ===' % data_name)\n",
    "  print('total squared error')\n",
    "  print(total_squared_error)\n",
    "  print('total absolute error')\n",
    "  print(total_absolute_error)\n",
    "  print('mean squared error')\n",
    "  print(mean_squared_error)\n",
    "  print('mean absolute error')\n",
    "  print(mean_absolute_error) \n",
    "  print('root mean squared error')\n",
    "  print(root_mean_squared_error) \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_statistics():\n",
    "  #event_count(small_set, 'small')\n",
    "  train_set = df.iloc[0:num_samples_training]\n",
    "  dev_set = df.iloc[num_samples_training:num_samples_training+num_samples_dev]\n",
    "  test_set = df.iloc[num_samples_training+num_samples_dev:]\n",
    "  event_count(train_set, 'train')\n",
    "  event_count(dev_set, 'dev')\n",
    "  event_count(test_set, 'test')\n",
    "  mse(train_set, 'train')\n",
    "  mse(dev_set, 'dev')\n",
    "  mse(test_set, 'test')\n",
    "\n",
    "#show_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    values = np.array(data)\n",
    "    values = values.reshape(-1,1)\n",
    "    values = values.astype('float32') \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(model_history, title):\n",
    "  plt.figure()\n",
    "  plt.plot(model_history.history['loss'], label='Train')\n",
    "  plt.plot(model_history.history['val_loss'], label='Dev')\n",
    "  plt.xlabel('Epochs'); plt.ylabel('Loss (mse)')\n",
    "  plt.title(title)\n",
    "  plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_pricescaler(data, Y_prevrawprice, fitted_scaler):\n",
    "    return fitted_scaler.inverse_transform(preprocess(data))\n",
    "\n",
    "def inverse_transform_percentdiff(data, Y_prevrawprice, fitted_scaler=None):\n",
    "    orig_prices = Y_prevrawprice\n",
    "    change = orig_prices * data\n",
    "    return orig_prices + change\n",
    "    #return fitted_scaler.inverse_transform(preprocess(data))\n",
    "\n",
    "#print(Y_test_prevrawprice)\n",
    "#print(inverse_transform_percentdiff(Y_test, Y_test_prevrawprice))\n",
    "\n",
    "inverse_transform = inverse_transform_percentdiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, Y_test, Y_prevrawprice, title, inverse=False, scaler=None):\n",
    "  y_hat = model.predict(X_test)\n",
    "\n",
    "  if inverse:\n",
    "      y_hat = inverse_transform(y_hat, Y_prevrawprice, scaler)\n",
    "      Y_test = inverse_transform(Y_test, Y_prevrawprice, scaler)\n",
    "\n",
    "  plt.plot(y_hat, label='Predicted')\n",
    "  plt.plot(Y_test, label='True')\n",
    "  plt.xlabel('Time'); \n",
    "\n",
    "  if inverse:\n",
    "      plt.ylabel('Price')\n",
    "  else:\n",
    "      plt.ylabel('RESCALED Price')\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE_RMSE(model, scaler, X_test, Y_test, Y_prevrawprice, model_name):\n",
    "  y_hat = model.predict(X_test)\n",
    "  y_hat_inverse = inverse_transform(y_hat, Y_prevrawprice, scaler)\n",
    "  Y_test_inverse = inverse_transform(Y_test, Y_prevrawprice, scaler)\n",
    "  mse = mean_squared_error(Y_test_inverse, y_hat_inverse)\n",
    "  rmse = np.sqrt(mean_squared_error(Y_test_inverse, y_hat_inverse))\n",
    "  print('%s:' % model_name)\n",
    "  print('Test MSE: %.3f' % mse)\n",
    "  print('Test RMSE: %.3f' % rmse)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "\n",
    "  # Train model\n",
    "  history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_split=0.05, verbose=verbose, shuffle=False)\n",
    "  #train_evaluate_showresults(history, model, model_name, \n",
    "  #                 X_train, Y_train, X_dev, Y_dev, X_test, Y_test,\n",
    "  #                 lag, batch_size, epochs, verbose)\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_showresults(history, model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "  # Plot losses, predictions, and calculate MSE and RMSE\n",
    "  plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_dev, Y_dev, Y_dev_prevrawprice, 'Test Predictions\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_dev, Y_dev, Y_dev_prevrawprice, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=price_scaler)\n",
    "  calculate_MSE_RMSE(model, price_scaler, X_dev, Y_dev, Y_dev_prevrawprice, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "    \n",
    "  # Train model\n",
    "  #history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "  #                    validation_split=0.05, verbose=verbose, shuffle=False)\n",
    "\n",
    "  # Plot losses, predictions, and calculate MSE and RMSE\n",
    "  #plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_test, Y_test, Y_test_prevrawprice, 'Test Predictions\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_test, Y_test, Y_test_prevrawprice, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=price_scaler)\n",
    "  calculate_MSE_RMSE(model, price_scaler, X_test, Y_test, Y_test_prevrawprice, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "#####################\n",
    "lag = 1\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adagrad' # sgd, adagrad, adam, rmsprop, adagrad\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "model_name = 'model_LAG-%s_LOSS-%s_OPT-%s_BATCHSIZE-%s_EPOCHS-%s' % (lag, loss, optimizer, batch_size, epochs)\n",
    "#####################\n",
    "\n",
    "\n",
    "LSTM_input_shape = [X_train.shape[1], X_train.shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL\n",
    "model = Sequential()\n",
    "\n",
    "##################### \n",
    "model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(50, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(256, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(200, return_sequences=False))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "#model.add(Dense(1, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Activation('linear'))\n",
    "#####################\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/evaluate model\n",
    "history = train_evaluate(model, model_name,\n",
    "               X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "               lag=lag, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_evaluate_showresults(history, model, model_name,\n",
    "               X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "               lag, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/evaluate model\n",
    "evaluate_test(model, model_name,\n",
    "              X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "              lag=lag, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
