{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4668662875047995537\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15597921895\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 1972345548902657558\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import lz4.frame\n",
    "import gzip\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from plumbum.cmd import rm\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotline(data):\n",
    "    plt.figure()\n",
    "    plt.plot(data)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def event_count(time_series, data_name):\n",
    "    time_series = time_series[['Fill Price (USD)']].values\n",
    "    upevents = 0\n",
    "    downevents = 0\n",
    "    sameprice = 0\n",
    "    prev_obv = time_series[0]\n",
    "    for obv in time_series[1:]:\n",
    "        if obv > prev_obv:\n",
    "            upevents += 1\n",
    "        elif obv < prev_obv:\n",
    "            downevents += 1\n",
    "        elif obv == prev_obv:\n",
    "            sameprice += 1\n",
    "        prev_obv = obv\n",
    "    print('=== Event counts on %s ===' % data_name)\n",
    "    print('upevents')\n",
    "    print(upevents)\n",
    "    print('downevents')\n",
    "    print(downevents)\n",
    "    print('sameprice')\n",
    "    print(sameprice)\n",
    "    print()\n",
    "\n",
    "def mse(time_series, data_name):\n",
    "    time_series = time_series[['Fill Price (USD)']].values\n",
    "    total_squared_error = 0\n",
    "    total_absolute_error = 0\n",
    "    prev_obv = time_series[0]\n",
    "    for obv in time_series[1:]:\n",
    "        total_squared_error += (obv - prev_obv)**2\n",
    "        total_absolute_error += abs(obv - prev_obv)\n",
    "        prev_obv = obv\n",
    "    num_predictions = len(time_series) - 1\n",
    "    mean_squared_error = total_squared_error / num_predictions\n",
    "    mean_absolute_error = total_absolute_error / num_predictions\n",
    "    root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "    print('=== baseline on %s ===' % data_name)\n",
    "    print('total squared error')\n",
    "    print(total_squared_error)\n",
    "    print('total absolute error')\n",
    "    print(total_absolute_error)\n",
    "    print('mean squared error')\n",
    "    print(mean_squared_error)\n",
    "    print('mean absolute error')\n",
    "    print(mean_absolute_error) \n",
    "    print('root mean squared error')\n",
    "    print(root_mean_squared_error) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_statistics():\n",
    "    #event_count(small_set, 'small')\n",
    "    train_set = df.iloc[0:num_samples_training]\n",
    "    dev_set = df.iloc[num_samples_training:num_samples_training+num_samples_dev]\n",
    "    test_set = df.iloc[num_samples_training+num_samples_dev:]\n",
    "    event_count(train_set, 'train')\n",
    "    event_count(dev_set, 'dev')\n",
    "    event_count(test_set, 'test')\n",
    "    mse(train_set, 'train')\n",
    "    mse(dev_set, 'dev')\n",
    "    mse(test_set, 'test')\n",
    "#show_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    values = np.array(data)\n",
    "    values = values.reshape(-1,1)\n",
    "    values = values.astype('float32') \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(model_history, title):\n",
    "    plt.figure()\n",
    "    plt.plot(model_history.history['loss'], label='Train')\n",
    "    plt.plot(model_history.history['val_loss'], label='Dev')\n",
    "    plt.xlabel('Epochs'); plt.ylabel('Loss (mse)')\n",
    "    plt.title(title)\n",
    "    plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_pricescaler(data, Y_prevrawprice, fitted_scaler):\n",
    "    return fitted_scaler.inverse_transform(preprocess(data))\n",
    "\n",
    "def inverse_transform_percentdiff(data, Y_prevrawprice, fitted_scaler=None):\n",
    "    orig_prices = Y_prevrawprice\n",
    "    change = orig_prices * data\n",
    "    return orig_prices + change\n",
    "    #return fitted_scaler.inverse_transform(preprocess(data))\n",
    "\n",
    "#print(Y_test_prevrawprice)\n",
    "#print(inverse_transform_percentdiff(Y_test, Y_test_prevrawprice))\n",
    "\n",
    "inverse_transform = inverse_transform_percentdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, Y_test, Y_prevrawprice, title, inverse=False, scaler=None):\n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    if inverse:\n",
    "        y_hat = inverse_transform(y_hat, Y_prevrawprice, scaler)\n",
    "        Y_test = inverse_transform(Y_test, Y_prevrawprice, scaler)\n",
    "\n",
    "    plt.plot(y_hat, label='Predicted')\n",
    "    plt.plot(Y_test, label='True')\n",
    "    plt.xlabel('Time'); \n",
    "\n",
    "    if inverse:\n",
    "        plt.ylabel('Price')\n",
    "    else:\n",
    "        plt.ylabel('RESCALED Price')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE_RMSE(model, scaler, X_test, Y_test, Y_prevrawprice, model_name):\n",
    "    y_hat = model.predict(X_test)\n",
    "    y_hat_inverse = inverse_transform(y_hat, Y_prevrawprice, scaler)\n",
    "    Y_test_inverse = inverse_transform(Y_test, Y_prevrawprice, scaler)\n",
    "    mse = mean_squared_error(Y_test_inverse, y_hat_inverse)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test_inverse, y_hat_inverse))\n",
    "    print('%s:' % model_name)\n",
    "    print('Test MSE: %.3f' % mse)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_split=0.05, verbose=verbose, shuffle=False)\n",
    "    #train_evaluate_showresults(history, model, model_name, \n",
    "    #                 X_train, Y_train, X_dev, Y_dev, X_test, Y_test,\n",
    "    #                 lag, batch_size, epochs, verbose)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_showresults(history, model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "    # Plot losses, predictions, and calculate MSE and RMSE\n",
    "    plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_dev, Y_dev, Y_dev_prevrawprice, 'Test Predictions\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_dev, Y_dev, Y_dev_prevrawprice, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=price_scaler)\n",
    "    calculate_MSE_RMSE(model, price_scaler, X_dev, Y_dev, Y_dev_prevrawprice, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, model_name, \n",
    "                   X_train, Y_train, Y_train_prevrawprice, X_dev, Y_dev, Y_dev_prevrawprice, X_test, Y_test, Y_test_prevrawprice,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "    # Plot losses, predictions, and calculate MSE and RMSE\n",
    "    #plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_test, Y_test, Y_test_prevrawprice, 'Test Predictions\\n(%s)' % model_name)\n",
    "    plot_predictions(model, X_test, Y_test, Y_test_prevrawprice, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=price_scaler)\n",
    "    calculate_MSE_RMSE(model, price_scaler, X_test, Y_test, Y_test_prevrawprice, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(X_train, loss, optimizer, num_LSTMs, num_units, dropout):\n",
    "    \n",
    "    LSTM_input_shape = [X_train.shape[1], X_train.shape[2]]\n",
    "\n",
    "    # DEFINE MODEL\n",
    "    model = Sequential()\n",
    "\n",
    "    if num_LSTMs == 2:\n",
    "            model.add(LSTM(num_units[0], input_shape=LSTM_input_shape, return_sequences=True))\n",
    "            model.add(Dropout(0.1))\n",
    "\n",
    "            model.add(LSTM(num_units[1], input_shape=LSTM_input_shape, return_sequences=False))\n",
    "            model.add(Dropout(0.1))\n",
    "        \n",
    "    if num_LSTMs == 3:\n",
    "            model.add(LSTM(num_units[0], input_shape=LSTM_input_shape, return_sequences=True))\n",
    "            model.add(Dropout(0.1))\n",
    "\n",
    "            model.add(LSTM(num_units[1], input_shape=LSTM_input_shape, return_sequences=True))\n",
    "            model.add(Dropout(0.1))\n",
    "            \n",
    "            model.add(LSTM(num_units[2], return_sequences=False))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    #model.add(Dense(1, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def load_data():\n",
    "    if not os.path.isfile('cboe/parquet_preprocessed_subset_only_BTCUSD_merged.parquet'):\n",
    "        files = sorted(glob('cboe/parquet_preprocessed_BTCUSD_merged/*.parquet'))\n",
    "        all_dataframes = []\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            df = pq.read_table(file).to_pandas()\n",
    "            all_dataframes.append(df)\n",
    "        result = pd.concat(all_dataframes)\n",
    "        pq.write_table(pa.Table.from_pandas(result), 'cboe/parquet_preprocessed_subset_only_BTCUSD_merged.parquet', compression='snappy')\n",
    "    df = pq.read_table('cboe/parquet_preprocessed_subset_only_BTCUSD_merged.parquet').to_pandas();\n",
    "    print(df.dtypes)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X(df):\n",
    "    n_all = df.shape[0]\n",
    "    n_train = round(n_all * 0.9)\n",
    "    n_dev   = round(n_all * 0.05)\n",
    "    n_test  = round(n_all * 0.05)\n",
    "    print('n_all:  ', n_all)\n",
    "    print('n_train:', n_train)\n",
    "    print('n_dev:  ', n_dev)\n",
    "    print('n_test: ', n_test)\n",
    "    \n",
    "    X_train = df.iloc[:n_train, 1:-1].values.astype('float32')[:, None, :]\n",
    "    X_dev   = df.iloc[n_train:n_train+n_dev, 1:-1].values.astype('float32')[:, None, :]\n",
    "    X_test  = df.iloc[n_train+n_dev:, 1:-1].values.astype('float32')[:, None, :]\n",
    "    print(X_train.shape)\n",
    "    print(X_dev.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    return X_train, X_dev, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Y(df):\n",
    "    n_all = df.shape[0]\n",
    "    n_train = round(n_all * 0.9)\n",
    "    n_dev   = round(n_all * 0.05)\n",
    "    n_test  = round(n_all * 0.05)\n",
    "    Y_train = df.iloc[:n_train, -1:].values.astype('float32')\n",
    "    Y_dev   = df.iloc[n_train:n_train+n_dev, -1:].values.astype('float32')\n",
    "    Y_test  = df.iloc[n_train+n_dev:, -1:].values.astype('float32')\n",
    "    print(Y_train.shape)\n",
    "    print(Y_dev.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    return Y_train, Y_dev, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_parquet(df, outfile):\n",
    "    pq.write_table(pa.Table.from_pandas(df), outfile, compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, history, X_train, X_dev, X_test, Y_train, Y_dev, Y_test):\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    dev_loss = history.history['val_loss'][-1]\n",
    "    test_loss = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_dev   = model.predict(X_dev)\n",
    "    y_hat_test  = model.predict(X_test)\n",
    "    \n",
    "    train_prop_correct = np.sum(np.sign(y_hat_test) == np.sign(Y_test)) / Y_test.shape[0]\n",
    "    dev_prop_correct   = np.sum(np.sign(y_hat_dev) == np.sign(Y_dev)) / Y_dev.shape[0]\n",
    "    test_prop_correct  = np.sum(np.sign(y_hat_train) == np.sign(Y_train)) / Y_train.shape[0]\n",
    "    \n",
    "    evaluation = [train_loss, dev_loss, test_loss, train_prop_correct, dev_prop_correct, test_prop_correct]\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_price                           float64\n",
      "percent_change                          float64\n",
      "buy_vol_mark_vs_fillLim                 float64\n",
      "buy_vol_placeLim_vs_fillLim             float64\n",
      "buy_freq_mark_vs_fillLim                float64\n",
      "buy_freq_placeLim_vs_fillLim            float64\n",
      "sell_vol_mark_vs_fillLim                float64\n",
      "sell_vol_placeLim_vs_fillLim            float64\n",
      "sell_freq_mark_vs_fillLim               float64\n",
      "sell_freq_placeLim_vs_fillLim           float64\n",
      "vol_markSells_vs_markBuys               float64\n",
      "vol_placeLimSells_vs_placeLimBuys       float64\n",
      "vol_CancelLimSells_vs_CancelLimBuys     float64\n",
      "freq_markSells_vs_markBuys              float64\n",
      "freq_placeLimSells_vs_placeLimBuys      float64\n",
      "freq_CancelLimSells_vs_CancelLimBuys    float64\n",
      "m0                                      float64\n",
      "m1                                      float64\n",
      "m2                                      float64\n",
      "m3                                      float64\n",
      "m4                                      float64\n",
      "m5                                      float64\n",
      "m6                                      float64\n",
      "m7                                      float64\n",
      "m8                                      float64\n",
      "m9                                      float64\n",
      "m10                                     float64\n",
      "m11                                     float64\n",
      "d0                                      float64\n",
      "d1                                      float64\n",
      "d2                                      float64\n",
      "d3                                      float64\n",
      "d4                                      float64\n",
      "d5                                      float64\n",
      "d6                                      float64\n",
      "h0                                      float64\n",
      "h1                                      float64\n",
      "h2                                      float64\n",
      "h3                                      float64\n",
      "h4                                      float64\n",
      "h5                                      float64\n",
      "h6                                      float64\n",
      "h7                                      float64\n",
      "h8                                      float64\n",
      "h9                                      float64\n",
      "h10                                     float64\n",
      "h11                                     float64\n",
      "h12                                     float64\n",
      "h13                                     float64\n",
      "h14                                     float64\n",
      "h15                                     float64\n",
      "h16                                     float64\n",
      "h17                                     float64\n",
      "h18                                     float64\n",
      "h19                                     float64\n",
      "h20                                     float64\n",
      "h21                                     float64\n",
      "h22                                     float64\n",
      "h23                                     float64\n",
      "y_percent_change                        float64\n",
      "dtype: object\n",
      "(1222293, 60)\n",
      "n_all:   1222293\n",
      "n_train: 1100064\n",
      "n_dev:   61115\n",
      "n_test:  61115\n",
      "(1100064, 1, 58)\n",
      "(61115, 1, 58)\n",
      "(61114, 1, 58)\n",
      "(1100064, 1)\n",
      "(61115, 1)\n",
      "(61114, 1)\n",
      "n_all:   1222293\n",
      "n_train: 1100064\n",
      "n_dev:   61115\n",
      "n_test:  61115\n",
      "(1100064, 1, 13)\n",
      "(61115, 1, 13)\n",
      "(61114, 1, 13)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "loss = 'mse'\n",
    "optimizers = ['adagrad', 'adam', 'rmsprop']\n",
    "batch_sizes = [2048, 8192, 16384]\n",
    "include_monthDayHour = [True, False]\n",
    "num_LSTMs = [2,3]\n",
    "num_units_2 = [[128, 256], [256, 256]]\n",
    "num_units_3 = [[128, 256, 256], [256, 256, 256], [256, 512, 512]]\n",
    "#amount_of_data = {'one_year', 'all'}\n",
    "#dropout = np.random.uniform(0.5, 0.05, num_LSTMs)\n",
    "dropout = 0.1\n",
    "\n",
    "# Load data\n",
    "df = load_data()\n",
    "X_train, X_dev, X_test = split_X(df) \n",
    "Y_train, Y_dev, Y_test = split_Y(df)\n",
    "\n",
    "df_noTime = df.iloc[:,1:16]\n",
    "X_train_noTime, X_dev_noTime, X_test_noTime = split_X(df_noTime) \n",
    "\n",
    "# Initialize output dataframe\n",
    "outfile = 'cboe/grid_search_dataSubset_merged.parquet'\n",
    "columns = ['num_epochs', 'loss', 'optimizer', 'batch_size', 'include_time', 'num_LSTMs', 'num_units',\n",
    "           'train_loss', 'dev_loss', 'test_loss', 'train_prop_correct', 'dev_prop_correct', 'test_prop_correct']\n",
    "df_output = pd.DataFrame(columns=columns)\n",
    "pq.write_table(pa.Table.from_pandas(df_output), outfile, compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 5s 5us/step - loss: 1.7434e-04 - val_loss: 6.4118e-06\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 7.1416e-06 - val_loss: 6.1949e-06\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 5.3021e-06 - val_loss: 6.1714e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 4.4695e-06 - val_loss: 6.1416e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 4.0259e-06 - val_loss: 6.1267e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 3.7324e-06 - val_loss: 6.1186e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 3.5461e-06 - val_loss: 6.1120e-06\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 3.4134e-06 - val_loss: 6.1068e-06\n",
      "Epoch 9/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 3.3097e-06 - val_loss: 6.1045e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 3.2288e-06 - val_loss: 6.1047e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 3.1662e-06 - val_loss: 6.1027e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 3.1035e-06 - val_loss: 6.0976e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 3.0578e-06 - val_loss: 6.0983e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 3.0301e-06 - val_loss: 6.0949e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.9896e-06 - val_loss: 6.0961e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.9536e-06 - val_loss: 6.0938e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.9303e-06 - val_loss: 6.0966e-06\n",
      "Epoch 18/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.9018e-06 - val_loss: 6.0913e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.8822e-06 - val_loss: 6.0911e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.8579e-06 - val_loss: 6.0917e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.8394e-06 - val_loss: 6.0902e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.8192e-06 - val_loss: 6.0901e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.8041e-06 - val_loss: 6.0898e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.7879e-06 - val_loss: 6.0901e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.7752e-06 - val_loss: 6.0921e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.7599e-06 - val_loss: 6.0893e-06\n",
      "Epoch 27/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.7439e-06 - val_loss: 6.0892e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.7270e-06 - val_loss: 6.0892e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 2.7186e-06 - val_loss: 6.0895e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.7073e-06 - val_loss: 6.0896e-06\n",
      "10 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 4s 4us/step - loss: 0.0011 - val_loss: 1.3406e-05\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 1.7152e-05 - val_loss: 7.0666e-06\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 1.3815e-05 - val_loss: 6.5106e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 1.2266e-05 - val_loss: 6.4098e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 1.1129e-05 - val_loss: 6.3642e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 1.0212e-05 - val_loss: 6.3307e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 9.4566e-06 - val_loss: 6.3143e-06\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 8.8080e-06 - val_loss: 6.2937e-06\n",
      "Epoch 9/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 8.2361e-06 - val_loss: 6.2722e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 7.7514e-06 - val_loss: 6.2545e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 7.3398e-06 - val_loss: 6.2511e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 6.9772e-06 - val_loss: 6.2344e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 6.6472e-06 - val_loss: 6.2288e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 6.3795e-06 - val_loss: 6.2185e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 6.0995e-06 - val_loss: 6.2094e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 5.8706e-06 - val_loss: 6.2017e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 5.6583e-06 - val_loss: 6.1955e-06\n",
      "Epoch 18/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 5.4850e-06 - val_loss: 6.1935e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 5.3033e-06 - val_loss: 6.1856e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 5.1469e-06 - val_loss: 6.1833e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 5.0081e-06 - val_loss: 6.1777e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.8842e-06 - val_loss: 6.1742e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.7672e-06 - val_loss: 6.1704e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.6485e-06 - val_loss: 6.1683e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.5439e-06 - val_loss: 6.1644e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.4623e-06 - val_loss: 6.1615e-06\n",
      "Epoch 27/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.3705e-06 - val_loss: 6.1587e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.2970e-06 - val_loss: 6.1568e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.2154e-06 - val_loss: 6.1546e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.1537e-06 - val_loss: 6.1524e-06\n",
      "20 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 7s 6us/step - loss: 2.2586e-05 - val_loss: 8.3443e-05\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 1.3531e-05 - val_loss: 6.5704e-06\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 5.6497e-06 - val_loss: 7.5563e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 7.3991e-06 - val_loss: 7.6837e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 6.6711e-06 - val_loss: 7.4656e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 6.8192e-06 - val_loss: 8.5021e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 5.8722e-06 - val_loss: 1.3148e-05\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 4.6841e-06 - val_loss: 1.0875e-05\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.4337e-06 - val_loss: 6.2357e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.3678e-06 - val_loss: 6.2075e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.4700e-06 - val_loss: 9.4956e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.4538e-06 - val_loss: 6.2621e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.5207e-06 - val_loss: 7.3675e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.1657e-06 - val_loss: 6.2060e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.1721e-06 - val_loss: 6.1576e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2014e-06 - val_loss: 6.1500e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2603e-06 - val_loss: 7.4745e-06\n",
      "Epoch 18/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.3396e-06 - val_loss: 6.4017e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2928e-06 - val_loss: 7.3205e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2773e-06 - val_loss: 6.2029e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2802e-06 - val_loss: 7.0606e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.3605e-06 - val_loss: 6.2904e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.3057e-06 - val_loss: 6.4784e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.4659e-06 - val_loss: 6.8851e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.3232e-06 - val_loss: 7.1973e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2584e-06 - val_loss: 6.3577e-06\n",
      "Epoch 27/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2268e-06 - val_loss: 6.3651e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.2028e-06 - val_loss: 6.7162e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.1574e-06 - val_loss: 6.5038e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.1504e-06 - val_loss: 6.1452e-06\n",
      "30 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 11s 10us/step - loss: 3.9572e-05 - val_loss: 6.3647e-06\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.5184e-06 - val_loss: 6.6168e-06\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3438e-06 - val_loss: 6.6611e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3392e-06 - val_loss: 6.7004e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3361e-06 - val_loss: 6.6990e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3338e-06 - val_loss: 6.6982e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3324e-06 - val_loss: 6.6955e-06\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3306e-06 - val_loss: 6.7932e-06\n",
      "Epoch 9/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3288e-06 - val_loss: 6.8833e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3273e-06 - val_loss: 6.9002e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3266e-06 - val_loss: 6.7363e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3263e-06 - val_loss: 6.7076e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3249e-06 - val_loss: 6.7705e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3241e-06 - val_loss: 6.7481e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3219e-06 - val_loss: 6.7220e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3224e-06 - val_loss: 6.6576e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3227e-06 - val_loss: 6.6771e-06\n",
      "Epoch 18/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3180e-06 - val_loss: 6.7764e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3207e-06 - val_loss: 6.7162e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3204e-06 - val_loss: 6.7041e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3207e-06 - val_loss: 6.7350e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3198e-06 - val_loss: 6.7539e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3190e-06 - val_loss: 6.7346e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3187e-06 - val_loss: 6.7776e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3177e-06 - val_loss: 6.9055e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3178e-06 - val_loss: 6.8935e-06\n",
      "Epoch 27/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3172e-06 - val_loss: 6.8951e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3164e-06 - val_loss: 6.9419e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3172e-06 - val_loss: 6.9135e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 5s 4us/step - loss: 2.3175e-06 - val_loss: 6.8294e-06\n",
      "40 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 11s 10us/step - loss: 1.2739e-04 - val_loss: 9.6629e-06\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.8047e-05 - val_loss: 1.3173e-05\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 1.5845e-05 - val_loss: 9.5198e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 9.6658e-06 - val_loss: 7.5927e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 6.1417e-06 - val_loss: 6.8172e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 4.2614e-06 - val_loss: 6.4158e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 3.2542e-06 - val_loss: 6.2747e-06\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.7398e-06 - val_loss: 6.2236e-06\n",
      "Epoch 9/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.4898e-06 - val_loss: 6.1737e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3817e-06 - val_loss: 6.1957e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3463e-06 - val_loss: 6.2294e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3370e-06 - val_loss: 6.2515e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3348e-06 - val_loss: 6.2588e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3333e-06 - val_loss: 6.2625e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3319e-06 - val_loss: 6.2588e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3304e-06 - val_loss: 6.2620e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3292e-06 - val_loss: 6.2582e-06\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3279e-06 - val_loss: 6.2586e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3267e-06 - val_loss: 6.2605e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3256e-06 - val_loss: 6.2587e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3246e-06 - val_loss: 6.2597e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3235e-06 - val_loss: 6.2583e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3226e-06 - val_loss: 6.2584e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3216e-06 - val_loss: 6.2573e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3209e-06 - val_loss: 6.2566e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3200e-06 - val_loss: 6.2572e-06\n",
      "Epoch 27/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.3192e-06 - val_loss: 6.2549e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3184e-06 - val_loss: 6.2558e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3178e-06 - val_loss: 6.2560e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 2s 1us/step - loss: 2.3170e-06 - val_loss: 6.2539e-06\n",
      "50 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 13s 12us/step - loss: 5.1609e-04 - val_loss: 6.5676e-06\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 1.0049e-05 - val_loss: 6.3355e-06\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 8.1845e-06 - val_loss: 6.2582e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 6.9631e-06 - val_loss: 6.2015e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 6.1053e-06 - val_loss: 6.1750e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 5.5035e-06 - val_loss: 6.1577e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 5.0144e-06 - val_loss: 6.1524e-06\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 4.6320e-06 - val_loss: 6.1371e-06\n",
      "Epoch 9/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 4.3365e-06 - val_loss: 6.1319e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 4.0868e-06 - val_loss: 6.1287e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.8861e-06 - val_loss: 6.1237e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.7051e-06 - val_loss: 6.1136e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.5619e-06 - val_loss: 6.1099e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.4325e-06 - val_loss: 6.1095e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.3192e-06 - val_loss: 6.1062e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.2246e-06 - val_loss: 6.1020e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.1388e-06 - val_loss: 6.0984e-06\n",
      "Epoch 18/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.0695e-06 - val_loss: 6.0962e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 3.0055e-06 - val_loss: 6.0943e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.9438e-06 - val_loss: 6.0928e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.8950e-06 - val_loss: 6.0932e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.8476e-06 - val_loss: 6.0901e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.8103e-06 - val_loss: 6.0904e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.7724e-06 - val_loss: 6.0895e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.7460e-06 - val_loss: 6.0882e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.7099e-06 - val_loss: 6.0865e-06\n",
      "Epoch 27/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.6861e-06 - val_loss: 6.0867e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.6576e-06 - val_loss: 6.0870e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.6392e-06 - val_loss: 6.0857e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 2s 2us/step - loss: 2.6175e-06 - val_loss: 6.0858e-06\n",
      "60 / 120\n",
      "Train on 1100064 samples, validate on 61115 samples\n",
      "Epoch 1/30\n",
      "1100064/1100064 [==============================] - 19s 17us/step - loss: 5.2361e-06 - val_loss: 6.1073e-06\n",
      "Epoch 2/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.2787e-06 - val_loss: 6.0596e-06\n",
      "Epoch 3/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.1804e-06 - val_loss: 6.0672e-06\n",
      "Epoch 4/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.1346e-06 - val_loss: 6.1419e-06\n",
      "Epoch 5/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.1129e-06 - val_loss: 6.1412e-06\n",
      "Epoch 6/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0971e-06 - val_loss: 6.0572e-06\n",
      "Epoch 7/30\n",
      "1100064/1100064 [==============================] - 5s 5us/step - loss: 2.0905e-06 - val_loss: 6.0552e-06\n",
      "Epoch 8/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0834e-06 - val_loss: 6.0568e-06\n",
      "Epoch 9/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0774e-06 - val_loss: 6.0684e-06\n",
      "Epoch 10/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0727e-06 - val_loss: 6.0690e-06\n",
      "Epoch 11/30\n",
      "1100064/1100064 [==============================] - 6s 6us/step - loss: 2.0701e-06 - val_loss: 6.0810e-06\n",
      "Epoch 12/30\n",
      "1100064/1100064 [==============================] - 6s 6us/step - loss: 2.0608e-06 - val_loss: 6.0690e-06\n",
      "Epoch 13/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0573e-06 - val_loss: 6.0598e-06\n",
      "Epoch 14/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0554e-06 - val_loss: 6.0641e-06\n",
      "Epoch 15/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0526e-06 - val_loss: 6.0592e-06\n",
      "Epoch 16/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0494e-06 - val_loss: 6.0627e-06\n",
      "Epoch 17/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0472e-06 - val_loss: 6.0821e-06\n",
      "Epoch 18/30\n",
      "1100064/1100064 [==============================] - 5s 5us/step - loss: 2.0459e-06 - val_loss: 6.0939e-06\n",
      "Epoch 19/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0444e-06 - val_loss: 6.0829e-06\n",
      "Epoch 20/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0425e-06 - val_loss: 6.0823e-06\n",
      "Epoch 21/30\n",
      "1100064/1100064 [==============================] - 5s 5us/step - loss: 2.0418e-06 - val_loss: 6.0832e-06\n",
      "Epoch 22/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0414e-06 - val_loss: 6.0840e-06\n",
      "Epoch 23/30\n",
      "1100064/1100064 [==============================] - 5s 5us/step - loss: 2.0410e-06 - val_loss: 6.0851e-06\n",
      "Epoch 24/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0409e-06 - val_loss: 6.0861e-06\n",
      "Epoch 25/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0408e-06 - val_loss: 6.0868e-06\n",
      "Epoch 26/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0408e-06 - val_loss: 6.0865e-06\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0408e-06 - val_loss: 6.0875e-06\n",
      "Epoch 28/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0408e-06 - val_loss: 6.0873e-06\n",
      "Epoch 29/30\n",
      "1100064/1100064 [==============================] - 6s 5us/step - loss: 2.0408e-06 - val_loss: 6.0882e-06\n",
      "Epoch 30/30\n",
      "1100064/1100064 [==============================] - 6s 6us/step - loss: 2.0408e-06 - val_loss: 6.0877e-06\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for include_time in include_monthDayHour:\n",
    "    if not include_time:\n",
    "        X_train = X_train_noTime\n",
    "        X_dev =   X_dev_noTime\n",
    "        X_test =  X_test_noTime\n",
    "\n",
    "    for optimizer in optimizers:\n",
    "        for batch_size in batch_sizes:\n",
    "            for num_LSTM in num_LSTMs:\n",
    "                if num_LSTM == 2:\n",
    "                    num_units = num_units_2\n",
    "                elif num_LSTM == 3:\n",
    "                    num_units = num_units_3\n",
    "                for n_units in num_units:\n",
    "                    # Load output dataframe\n",
    "                    df_output = pq.read_table(outfile).to_pandas()\n",
    "                    \n",
    "                    # Initialize model\n",
    "                    model = initialize_model(X_train, loss, optimizer, num_LSTM, n_units, dropout)\n",
    "                    \n",
    "                    # Train model\n",
    "                    if count%10==0:\n",
    "                        verbose=1\n",
    "                        print(count, '/', 120)\n",
    "                    else:\n",
    "                        verbose=0\n",
    "                    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                      validation_data=(X_dev, Y_dev), verbose=verbose, shuffle=False) \n",
    "                    \n",
    "                    # Evaluate model\n",
    "                    evaluate = evaluate_model(model, history, X_train, X_dev, X_test, Y_train, Y_dev, Y_test)\n",
    "                    \n",
    "                    # Write to dataframe and save\n",
    "                    row = [num_epochs, loss, optimizer, batch_size, include_time, num_LSTM, str(n_units)]\n",
    "                    row.extend(evaluate)\n",
    "                    df_output.loc[len(df_output)] = row\n",
    "                    df_to_parquet(df_output, outfile)\n",
    "                    \n",
    "                    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2048 batch, 3 cells, numunits[2]\n",
    "# HYPERPARAMETERS\n",
    "#####################\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adagrad'\n",
    "batch_size = 2048\n",
    "epochs = 10\n",
    "\n",
    "num_LSTMs = 3\n",
    "num_units = num_units_3[2]\n",
    "model = initialize_model(X_train, loss, optimizer, num_LSTMs, num_units, dropout)\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, Y_dev), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
