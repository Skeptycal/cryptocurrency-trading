{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import paratext\n",
    "import pandas as pd\n",
    "import lz4.frame\n",
    "import gzip\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "filepath = 'cboe/lz4_test/BTCUSD_order_book_20170627.csv.lz4'\n",
    "#filepath = 'cboe/lz4_test/BTCUSD_order_book_20170627.csv.gz'\n",
    "df = pandas.read_csv(io.TextIOWrapper(lz4.frame.open(filepath)))\n",
    "#df = pandas.read_csv(filepath)\n",
    "#df = paratext.load_csv_to_pandas(gzip.open(filepath).read())\n",
    "print((df))\n",
    "'''\n",
    "\n",
    "from glob import glob\n",
    "from plumbum.cmd import rm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID                        int64\n",
      "Event Date                     object\n",
      "Event Time                     object\n",
      "Event Millis                    int64\n",
      "Order ID                        int64\n",
      "Execution Options              object\n",
      "Event Type                     object\n",
      "Symbol                         object\n",
      "Order Type                     object\n",
      "Side                           object\n",
      "Limit Price (USD)             float64\n",
      "Original Quantity (BTC)       float64\n",
      "Gross Notional Value (USD)    float64\n",
      "Fill Price (USD)              float64\n",
      "Fill Quantity (BTC)           float64\n",
      "Total Exec Quantity (BTC)     float64\n",
      "Remaining Quantity (BTC)      float64\n",
      "Avg Price (USD)               float64\n",
      "dtype: object\n",
      "(9384110, 18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pq.read_table('cboe/parquet_fills_only_BTCUSD.parquet').to_pandas()\n",
    "print(df.dtypes)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_samples = df.shape[0]\n",
    "#num_samples_training = round(num_samples * 0.9)\n",
    "#num_samples_dev = round(num_samples * 0.05)\n",
    "#num_samples_test = round(num_samples * 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = df.iloc[0:num_samples_training]\n",
    "#dev_set = df.iloc[num_samples_training:num_samples_training+num_samples_dev]\n",
    "#test_set = df.iloc[num_samples_training+num_samples_dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_set = df.iloc[0:10]\n",
    "#print(small_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min_price(fulldata):\n",
    "  max_price = data[['Fill Price (USD)']].max().item()\n",
    "  min_price = data[['Fill Price (USD)']].min().item()\n",
    "  return {\n",
    "    'max': max_price,\n",
    "    'min': min_price\n",
    "  }\n",
    "\n",
    "def extract_price_features(fulldata):\n",
    "  data = fulldata[['Fill Price (USD)', 'Side', 'Order Type']].copy()\n",
    "  length = data.shape[0]\n",
    "  data['isbuy'] = pd.get_dummies(data['Side'])['buy'].values\n",
    "  data['ismarket'] = pd.get_dummies(data['Order Type'])['market'].values\n",
    "  return data[['Fill Price (USD)', 'isbuy', 'ismarket']].iloc[:length - 1].values.astype('float32')[:, None, :]\n",
    "\n",
    "extract_features = extract_price_features\n",
    "\n",
    "#small_features = extract_features(small_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = extract_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = all_features.shape[0]\n",
    "num_samples_training = round(num_samples * 0.9)\n",
    "num_samples_dev = round(num_samples * 0.05)\n",
    "num_samples_test = round(num_samples * 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_features[0:num_samples_training, :]\n",
    "X_dev = all_features[num_samples_training:num_samples_training+num_samples_dev, :]\n",
    "X_test = all_features[num_samples_training+num_samples_dev:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_y_rawprice(fulldata):\n",
    "  prices = fulldata[['Fill Price (USD)']].values.astype('float32')\n",
    "  return np.delete(prices, 0, axis=0)\n",
    "  #return np.insert(prices, 0, prices[0])\n",
    "\n",
    "extract_y = extract_y_rawprice\n",
    "\n",
    "#print(len(extract_y(small_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = extract_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9384109, 1, 3)\n",
      "(9384109, 1)\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(all_features.shape)\n",
    "print(all_y.shape)\n",
    "print(all_features.dtype)\n",
    "print(all_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = all_y[0:num_samples_training, :]\n",
    "Y_dev = all_y[num_samples_training:num_samples_training+num_samples_dev, :]\n",
    "Y_test = all_y[num_samples_training+num_samples_dev:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[242.5    1.     0.  ]]\n",
      "\n",
      " [[242.5    0.     1.  ]]\n",
      "\n",
      " [[242.95   1.     0.  ]]\n",
      "\n",
      " [[242.95   0.     0.  ]]\n",
      "\n",
      " [[242.96   0.     0.  ]]\n",
      "\n",
      " [[242.96   1.     0.  ]]\n",
      "\n",
      " [[242.96   1.     0.  ]]\n",
      "\n",
      " [[242.96   0.     0.  ]]\n",
      "\n",
      " [[242.96   1.     0.  ]]\n",
      "\n",
      " [[242.96   0.     0.  ]]]\n",
      "[[242.5 ]\n",
      " [242.95]\n",
      " [242.95]\n",
      " [242.96]\n",
      " [242.96]\n",
      " [242.96]\n",
      " [242.96]\n",
      " [242.96]\n",
      " [242.96]\n",
      " [243.  ]]\n"
     ]
    }
   ],
   "source": [
    "X_sample = all_features[0:10]\n",
    "Y_sample = all_y[0:10]\n",
    "print(X_sample)\n",
    "print(Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_count(time_series, data_name):\n",
    "  time_series = time_series[['Fill Price (USD)']].values\n",
    "  upevents = 0\n",
    "  downevents = 0\n",
    "  sameprice = 0\n",
    "  prev_obv = time_series[0]\n",
    "  for obv in time_series[1:]:\n",
    "      if obv > prev_obv:\n",
    "          upevents += 1\n",
    "      elif obv < prev_obv:\n",
    "          downevents += 1\n",
    "      elif obv == prev_obv:\n",
    "          sameprice += 1\n",
    "      prev_obv = obv\n",
    "  print('=== Event counts on %s ===' % data_name)\n",
    "  print('upevents')\n",
    "  print(upevents)\n",
    "  print('downevents')\n",
    "  print(downevents)\n",
    "  print('sameprice')\n",
    "  print(sameprice)\n",
    "  print()\n",
    "\n",
    "def mse(time_series, data_name):\n",
    "  time_series = time_series[['Fill Price (USD)']].values\n",
    "  total_squared_error = 0\n",
    "  total_absolute_error = 0\n",
    "  prev_obv = time_series[0]\n",
    "  for obv in time_series[1:]:\n",
    "    total_squared_error += (obv - prev_obv)**2\n",
    "    total_absolute_error += abs(obv - prev_obv)\n",
    "    prev_obv = obv\n",
    "  num_predictions = len(time_series) - 1\n",
    "  mean_squared_error = total_squared_error / num_predictions\n",
    "  mean_absolute_error = total_absolute_error / num_predictions\n",
    "  root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "  print('=== baseline on %s ===' % data_name)\n",
    "  print('total squared error')\n",
    "  print(total_squared_error)\n",
    "  print('total absolute error')\n",
    "  print(total_absolute_error)\n",
    "  print('mean squared error')\n",
    "  print(mean_squared_error)\n",
    "  print('mean absolute error')\n",
    "  print(mean_absolute_error) \n",
    "  print('root mean squared error')\n",
    "  print(root_mean_squared_error) \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_statistics():\n",
    "  #event_count(small_set, 'small')\n",
    "  event_count(train_set, 'train')\n",
    "  event_count(dev_set, 'dev')\n",
    "  event_count(test_set, 'test')\n",
    "  mse(train_set, 'train')\n",
    "  mse(dev_set, 'dev')\n",
    "  mse(test_set, 'test')\n",
    "\n",
    "#show_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(model_history, title):\n",
    "  plt.figure()\n",
    "  plt.plot(model_history.history['loss'], label='Train')\n",
    "  plt.plot(model_history.history['val_loss'], label='Dev')\n",
    "  plt.xlabel('Epochs'); plt.ylabel('Loss (mse)')\n",
    "  plt.title(title)\n",
    "  plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, Y_test, title, inverse=False, scaler=None):\n",
    "  y_hat = model.predict(X_test)\n",
    "\n",
    "  if inverse:\n",
    "      y_hat = inverse_transform(y_hat, scaler)\n",
    "      Y_test = inverse_transform(Y_test, scaler)\n",
    "\n",
    "  plt.plot(y_hat, label='Predicted')\n",
    "  plt.plot(Y_test, label='True')\n",
    "  plt.xlabel('Time'); \n",
    "\n",
    "  if inverse:\n",
    "      plt.ylabel('Price')\n",
    "  else:\n",
    "      plt.ylabel('RESCALED Price')\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE_RMSE(model, scaler, X_test, Y_test, model_name):\n",
    "  y_hat = model.predict(X_test)\n",
    "  y_hat_inverse = inverse_transform(y_hat, scaler)\n",
    "  Y_test_inverse = inverse_transform(Y_test, scaler)\n",
    "  mse = mean_squared_error(Y_test_inverse, y_hat_inverse)\n",
    "  rmse = np.sqrt(mean_squared_error(Y_test_inverse, y_hat_inverse))\n",
    "  print('%s:' % model_name)\n",
    "  print('Test MSE: %.3f' % mse)\n",
    "  print('Test RMSE: %.3f' % rmse)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model, model_name, \n",
    "                   X_train, Y_train, X_dev, Y_dev, X_test, Y_test,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "\n",
    "  # Train model\n",
    "  history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_split=0.05, verbose=verbose, shuffle=False)\n",
    "\n",
    "  # Plot losses, predictions, and calculate MSE and RMSE\n",
    "  plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_dev, Y_dev, 'Test Predictions\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_dev, Y_dev, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=scaler)\n",
    "  #calculate_MSE_RMSE(model, scaler, X_dev, Y_dev, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, model_name, \n",
    "                   X_train, Y_train, X_dev, Y_dev, X_test, Y_test,\n",
    "                   lag=10, batch_size=100, epochs=10, verbose=1):\n",
    "    \n",
    "  # Train model\n",
    "  #history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "  #                    validation_split=0.05, verbose=verbose, shuffle=False)\n",
    "\n",
    "  # Plot losses, predictions, and calculate MSE and RMSE\n",
    "  #plot_losses(history, 'Loss\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_test, Y_test, 'Test Predictions\\n(%s)' % model_name)\n",
    "  plot_predictions(model, X_test, Y_test, 'Test Predictions\\n(%s)' % model_name, inverse=True, scaler=scaler)\n",
    "  calculate_MSE_RMSE(model, scaler, X_test, Y_test, '%s' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "#####################\n",
    "lag = 1\n",
    "loss = 'mean_squared_error'\n",
    "optimizer = 'adagrad' # sgd, adagrad, adam, rmsprop, adagrad\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "model_name = 'model_LAG-%s_LOSS-%s_OPT-%s_BATCHSIZE-%s_EPOCHS-%s' % (lag, loss, optimizer, batch_size, epochs)\n",
    "#####################\n",
    "\n",
    "\n",
    "LSTM_input_shape = [X_train.shape[1], X_train.shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL\n",
    "model = Sequential()\n",
    "\n",
    "##################### \n",
    "model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(50, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(200, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(LSTM(256, input_shape=LSTM_input_shape, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(200, return_sequences=False))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "#model.add(Dense(1, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Activation('linear'))\n",
    "#####################\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8445698, 1, 3)\n",
      "(8445698, 1)\n",
      "[[[2.42500e+02 1.00000e+00 0.00000e+00]]\n",
      "\n",
      " [[2.42500e+02 0.00000e+00 1.00000e+00]]\n",
      "\n",
      " [[2.42950e+02 1.00000e+00 0.00000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[6.01188e+03 0.00000e+00 0.00000e+00]]\n",
      "\n",
      " [[6.01188e+03 1.00000e+00 0.00000e+00]]\n",
      "\n",
      " [[6.01188e+03 0.00000e+00 0.00000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3635582174957065690\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7937798964\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 5197763065719642757\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8023413 samples, validate on 422285 samples\n",
      "Epoch 1/20\n",
      "8022800/8023413 [============================>.] - ETA: 0s - loss: 10880934.8458"
     ]
    }
   ],
   "source": [
    "# Train/evaluate model\n",
    "train_evaluate(model, model_name,\n",
    "               X_train, Y_train, X_dev, Y_dev, X_test, Y_test,\n",
    "               lag=lag, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
